{
  "paragraphs": [
    {
      "text": "print(s\"\"\"%html\n<center>\n    <h1><a href=\"http://diplodatos.famaf.unc.edu.ar/\">Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones</a></h1>\n    <h2>Curso <a href=\"https://sites.google.com/view/eleccion-optativas-diplodatos/programaci%C3%B3n-distribu%C3%ADda-sobre-grandes-vol%C3%BAmenes-de-datos\">Programación Distribuida sobre Grandes Volúmenes de Datos</a></h2>\n</center>\n\n<br>\n\n<h3 style=\"text-align:center;\"> Damián Barsotti  </h3>\n\n<h3 style=\"text-align:center;\">\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    Facultad de Matemática Astronomía Física y Computación\n    </a>\n<br/>\n    <a href=\"http://www.unc.edu.ar\">\n    Universidad Nacional de Córdoba\n    </a>\n<br/>\n    <center>\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    <img src=\"$baseDir/comun/logo%20UNC%20FAMAF%202016.png\" alt=\"Drawing\" style=\"width:50%;\"/>\n    </a>\n    </center>\n</h3>\n\n<p style=\"font-size:15px;\">\n    <br />\n        This work is licensed under a\n        <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">\n        <img alt=\"Creative Commons License\" style=\"border-width:0;vertical-align:middle;float:right\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" />\n    </a>\n</p>\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<center>\n    <h1><a href=\"http://diplodatos.famaf.unc.edu.ar/\">Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones</a></h1>\n    <h2>Curso <a href=\"https://sites.google.com/view/eleccion-optativas-diplodatos/programaci%C3%B3n-distribu%C3%ADda-sobre-grandes-vol%C3%BAmenes-de-datos\">Programación Distribuida sobre Grandes Volúmenes de Datos</a></h2>\n</center>\n\n<br>\n\n<h3 style=\"text-align:center;\"> Damián Barsotti  </h3>\n\n<h3 style=\"text-align:center;\">\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    Facultad de Matemática Astronomía Física y Computación\n    </a>\n<br/>\n    <a href=\"http://www.unc.edu.ar\">\n    Universidad Nacional de Córdoba\n    </a>\n<br/>\n    <center>\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    <img src=\"https://bitbucket.org/bigdata_famaf/diplodatos_bigdata/raw/HEAD/clases/comun/logo%20UNC%20FAMAF%202016.png\" alt=\"Drawing\" style=\"width:50%;\"/>\n    </a>\n    </center>\n</h3>\n\n<p style=\"font-size:15px;\">\n    <br />\n        This work is licensed under a\n        <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">\n        <img alt=\"Creative Commons License\" style=\"border-width:0;vertical-align:middle;float:right\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" />\n    </a>\n</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639457_2046877511",
      "id": "20171010-191319_1407757246",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "focus": true,
      "$$hashKey": "object:6886"
    },
    {
      "text": "%md\n\n# Spark Core\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h1>Spark Core</h1>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639458_350403761",
      "id": "20171013-124120_1151991544",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6887"
    },
    {
      "text": "%md\n\n<br>\n### Veremos conceptos básicos  aplicables a otras librerías de [Spark](http://spark.apache.org):\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 6,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<br>\n<h3>Veremos conceptos básicos aplicables a otras librerías de <a href=\"http://spark.apache.org\">Spark</a>:</h3>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639459_716685937",
      "id": "20171013-125344_626244712",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6888"
    },
    {
      "text": "print(s\"\"\"%html\n&nbsp;\n<img src=\"$baseDir/02_spark_core/core_stack.png\" alt=\"Drawing\" style=\"width: 100%;\"/>\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionSupport": true,
          "completionKey": "TAB"
        },
        "colWidth": 6,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "&nbsp;\n<img src=\"https://bitbucket.org/bigdata_famaf/diplodatos_bigdata/raw/HEAD/clases/02_spark_core/core_stack.png\" alt=\"Drawing\" style=\"width: 100%;\"/>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639459_93356364",
      "id": "20171013-125319_1987010321",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6889"
    },
    {
      "text": "%md\n\n## ~.- Conceptos básicos\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>~.- Conceptos básicos</h2>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639460_847987811",
      "id": "20171013-125336_1933366904",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6890"
    },
    {
      "text": "%md\n\n### Driver\n\nToda aplicación Spark tiene un programa **driver**:\n\n* lanza las operaciones en el cluster,\n* contiene nuestro **programa**\n    - define datos distribuidos y les aplica operaciones.\n\n> En Zeppelin escribimos un *programa driver* que de forma interactiva ejecuta las operaciones que queremos correr.\n\n### Executors\n\nEl driver maneja y envía tareas a **executors** en los **worker nodes** (computadoras del cluster o threads en modo local).\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 6,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Driver</h3>\n<p>Toda aplicación Spark tiene un programa <strong>driver</strong>:</p>\n<ul>\n<li>lanza las operaciones en el cluster,</li>\n<li>contiene nuestro <strong>programa</strong>\n<ul>\n<li>define datos distribuidos y les aplica operaciones.</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>En Zeppelin escribimos un <em>programa driver</em> que de forma interactiva ejecuta las operaciones que queremos correr.</p>\n</blockquote>\n<h3>Executors</h3>\n<p>El driver maneja y envía tareas a <strong>executors</strong> en los <strong>worker nodes</strong> (computadoras del cluster o threads en modo local).</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639460_512693104",
      "id": "20171013-130405_1538728027",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6891"
    },
    {
      "text": "println(s\"\"\"%html\n<img src=\"$baseDir/01_intro_spark/driver_exec.png\" alt=\"Drawing\" style=\"width: 60%;\"/>\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<img src=\"https://bitbucket.org/bigdata_famaf/diplodatos_bigdata/raw/HEAD/clases/01_intro_spark/driver_exec.png\" alt=\"Drawing\" style=\"width: 60%;\"/>\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639460_79809683",
      "id": "20171013-123200_262582034",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6892"
    },
    {
      "text": "%md\n### SparkContext\n\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>SparkContext</h3>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639460_1988432032",
      "id": "20171013-130511_1848331242",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6893"
    },
    {
      "text": "%md\n\n&nbsp;\n\n* Los programas en el driver se conectan al cluster Spark a través de un objeto `SparkContext`\n* Le dice a Spark como conectarce con el cluster (o a los distintos threads en modo local)\n    - (representa la conección al cluster) \n* En Zeppelin (y shell) está predefinida la variable `sc` de tipo `SparkContext`\n    - otros programas deben crearla con `new`\n\n![](https://bitbucket.org/bigdata_famaf/diplodatos_bigdata/raw/HEAD/clases/02_spark_core/cluster-overview.png)\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 6,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>&nbsp;</p>\n<ul>\n  <li>Los programas en el driver se conectan al cluster Spark a través de un objeto <code>SparkContext</code></li>\n  <li>Le dice a Spark como conectarce con el cluster (o a los distintos threads en modo local)\n    <ul>\n      <li>(representa la conección al cluster)</li>\n    </ul>\n  </li>\n  <li>En Zeppelin (y shell) está predefinida la variable <code>sc</code> de tipo <code>SparkContext</code>\n    <ul>\n      <li>otros programas deben crearla con <code>new</code></li>\n    </ul>\n  </li>\n</ul>\n<p><img src=\"https://bitbucket.org/bigdata_famaf/diplodatos_bigdata/raw/HEAD/clases/02_spark_core/cluster-overview.png\" /></p>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639461_1269652041",
      "id": "20171013-160636_1142900877",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6894"
    },
    {
      "text": "%pyspark\n\nprint(sc.defaultParallelism)\nprint(sc.master)\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6,
        "editorMode": "ace/mode/python",
        "fontSize": 14,
        "editorHide": false,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639461_484132231",
      "id": "20171013-131916_230493933",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6895"
    },
    {
      "title": "sc.master",
      "text": "%md\n|master            |descripción                                               |\n|------------------|----------------------------------------------------------|\n|local             |Spark corre localmente con un solo worker (no paralelismo)|\n|local[K]          |Spark corre localmente con K threads                      |\n|spark://HOST:PORT |se conecta a un cluster Spark                             |\n|mesos://HOST:PORT |se conecta a un cluster Mesos                             |\n|yarn              |se conecta a un cluster Hadoop Yarn                       |\n|...               |...                                                       |\n\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 6,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "master": "string",
                      "descripción": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<table>\n  <thead>\n    <tr>\n      <th>master </th>\n      <th>descripción </th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>local </td>\n      <td>Spark corre localmente con un solo worker (no paralelismo)</td>\n    </tr>\n    <tr>\n      <td>local[K] </td>\n      <td>Spark corre localmente con K threads </td>\n    </tr>\n    <tr>\n      <td><a href=\"spark://HOST:PORT\">spark://HOST:PORT</a> </td>\n      <td>se conecta a un cluster Spark </td>\n    </tr>\n    <tr>\n      <td><a href=\"mesos://HOST:PORT\">mesos://HOST:PORT</a> </td>\n      <td>se conecta a un cluster Mesos </td>\n    </tr>\n    <tr>\n      <td>yarn </td>\n      <td>se conecta a un cluster Hadoop Yarn </td>\n    </tr>\n    <tr>\n      <td>&hellip; </td>\n      <td>&hellip; </td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639462_30967839",
      "id": "20191123-192357_508683745",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6896"
    },
    {
      "text": "%md\n\n## ~.- Resilient Distributed Dataset (RDD)\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>~.- Resilient Distributed Dataset (RDD)</h2>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639462_1176921233",
      "id": "20171013-130245_542901367",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6897"
    },
    {
      "text": "%md\n* **Contenedores** de objetos **inmutables**, distribuidos en el cluster (contiene los datos)\n\n* Creados con el SparkContext `sc`.\n    - al cargar datasets a Spark\n    - por transformaciones comunes (`map`, `filter`, ...) o binarias (`union`, `intersection`, ...).\n\n* Ante fallas se reconstruyen (resilencia).\n* **Importante**: todo lo que no derive del `SparkContext` corre solo en el **driver**.\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<ul>\n  <li>\n  <p><strong>Contenedores</strong> de objetos <strong>inmutables</strong>, distribuidos en el cluster (contiene los datos)</p></li>\n  <li>\n    <p>Creados con el SparkContext <code>sc</code>.</p>\n    <ul>\n      <li>al cargar datasets a Spark</li>\n      <li>por transformaciones comunes (<code>map</code>, <code>filter</code>, &hellip;) o binarias (<code>union</code>, <code>intersection</code>, &hellip;).</li>\n    </ul>\n  </li>\n  <li>\n  <p>Ante fallas se reconstruyen (resilencia).</p></li>\n  <li><strong>Importante</strong>: todo lo que no derive del <code>SparkContext</code> corre solo en el <strong>driver</strong>.</li>\n</ul>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639462_1675332179",
      "id": "20171013-161530_19251643",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6898"
    },
    {
      "title": "Ejemplo log analysis",
      "text": "%pyspark\n\ninputRDD = sc.textFile(\"./logs/\") # RDD de entrada\n\n# se crea un nuevo RDD:\nerrorRDD = inputRDD.filter(lambda line: \"ERROR\" in line) \n\n# se crea otro nuevo RDD\nconfigRDD = inputRDD.filter(lambda line: \"config\" in line) \n\nerrOrConfRDD = errorRDD.union(configRDD) \n\nfor ln, l in enumerate(errOrConfRDD.collect()):\n    print(\"Linea {}:\".format(ln), l)\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-24T11:57:28+0000",
      "progress": 100,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6,
        "editorMode": "ace/mode/python",
        "fontSize": 14,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Linea 0:  WARN [2022-10-24 00:00:57,110] ({SchedulerFactory20} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666564853357_1901912691 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 1:  INFO [2022-10-24 00:00:57,189] ({SchedulerFactory20} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 2:  WARN [2022-10-24 00:01:10,451] ({SchedulerFactory39} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666564853357_1901912691 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 3:  INFO [2022-10-24 00:01:10,543] ({SchedulerFactory39} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 4:  WARN [2022-10-24 00:02:09,336] ({SchedulerFactory78} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666564853357_1901912691 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 5:  INFO [2022-10-24 00:02:09,424] ({SchedulerFactory78} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 6:  WARN [2022-10-24 00:12:28,295] ({SchedulerFactory43} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666564853357_1901912691 is finished, status: ERROR, exception: null, result: %text \u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_319/3966295984.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\nLinea 7:  INFO [2022-10-24 00:12:28,379] ({SchedulerFactory43} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 8: ERROR [2022-10-15 13:20:08,162] ({qtp793315160-28} LuceneSearch.java[query]:135) - Failed to open index dir MMapDirectory@/tmp/zeppelin-index lockFactory=org.apache.lucene.store.NativeFSLockFactory@5eda3157, make sure indexing finished OK\nLinea 9: ERROR [2022-10-15 13:20:10,610] ({qtp793315160-47} LuceneSearch.java[query]:135) - Failed to open index dir MMapDirectory@/tmp/zeppelin-index lockFactory=org.apache.lucene.store.NativeFSLockFactory@5eda3157, make sure indexing finished OK\nLinea 10:  WARN [2022-10-18 13:52:22,750] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_328/2334447862.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\nLinea 11:  INFO [2022-10-18 13:52:22,798] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 12:  WARN [2022-10-18 13:52:43,006] ({SchedulerFactory4} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_328/2016192307.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\nLinea 13:  INFO [2022-10-18 13:52:43,044] ({SchedulerFactory4} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 14:  WARN [2022-10-18 14:54:37,397] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 15:  INFO [2022-10-18 14:54:37,641] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 16:  WARN [2022-10-18 14:58:44,294] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_324/4004225881.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\nLinea 17:  INFO [2022-10-18 14:58:44,393] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 18:  WARN [2022-10-18 14:59:01,308] ({SchedulerFactory3} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 19:  INFO [2022-10-18 14:59:01,427] ({SchedulerFactory3} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 20:  WARN [2022-10-18 15:01:08,538] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_324/1550924481.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\nLinea 21:  INFO [2022-10-18 15:01:08,610] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 22:  WARN [2022-10-18 15:01:14,756] ({SchedulerFactory4} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_324/1101581197.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\nLinea 23:  INFO [2022-10-18 15:01:14,874] ({SchedulerFactory4} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 24:  WARN [2022-10-18 15:01:23,001] ({SchedulerFactory3} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 25:  INFO [2022-10-18 15:01:23,079] ({SchedulerFactory3} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 26:  WARN [2022-10-18 15:04:09,175] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 27:  INFO [2022-10-18 15:04:09,296] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 28:  WARN [2022-10-18 15:05:44,339] ({SchedulerFactory6} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 29:  INFO [2022-10-18 15:05:44,458] ({SchedulerFactory6} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 30:  WARN [2022-10-18 15:06:07,054] ({SchedulerFactory4} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 31:  INFO [2022-10-18 15:06:07,141] ({SchedulerFactory4} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 32:  WARN [2022-10-19 14:39:38,064] ({SchedulerFactory3} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 33:  INFO [2022-10-19 14:39:38,147] ({SchedulerFactory3} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 34:  WARN [2022-10-19 14:40:28,552] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_336/3606369458.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\nLinea 35:  INFO [2022-10-19 14:40:28,589] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 36:  WARN [2022-10-19 14:40:38,255] ({SchedulerFactory4} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 37:  INFO [2022-10-19 14:40:38,296] ({SchedulerFactory4} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 38:  WARN [2022-10-19 14:41:34,752] ({SchedulerFactory3} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_336/3740540697.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\nLinea 39:  INFO [2022-10-19 14:41:34,780] ({SchedulerFactory3} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 40:  WARN [2022-10-19 14:41:51,697] ({SchedulerFactory5} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 41:  INFO [2022-10-19 14:41:51,724] ({SchedulerFactory5} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 42:  WARN [2022-10-19 14:41:57,187] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 43:  INFO [2022-10-19 14:41:57,221] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 44:  WARN [2022-10-19 14:42:31,025] ({SchedulerFactory6} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666100897380_1473405501 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 45:  INFO [2022-10-19 14:42:31,089] ({SchedulerFactory6} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 46:  WARN [2022-10-23 15:31:40,471] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 47:  INFO [2022-10-23 15:31:40,557] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 48:  WARN [2022-10-23 15:31:57,119] ({SchedulerFactory3} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 49:  INFO [2022-10-23 15:31:57,189] ({SchedulerFactory3} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 50:  WARN [2022-10-23 15:33:07,659] ({SchedulerFactory4} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 51:  INFO [2022-10-23 15:33:07,718] ({SchedulerFactory4} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 52:  WARN [2022-10-23 15:33:31,046] ({SchedulerFactory3} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 53:  INFO [2022-10-23 15:33:31,103] ({SchedulerFactory3} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 54:  WARN [2022-10-23 15:33:52,379] ({SchedulerFactory5} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 55:  INFO [2022-10-23 15:33:52,424] ({SchedulerFactory5} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 56:  WARN [2022-10-23 15:34:09,696] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 57:  INFO [2022-10-23 15:34:09,748] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 58:  WARN [2022-10-23 15:35:08,954] ({SchedulerFactory4} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_317/1245887059.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\nLinea 59:  INFO [2022-10-23 15:35:08,989] ({SchedulerFactory4} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 60:  WARN [2022-10-23 15:35:49,875] ({SchedulerFactory7} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 61:  INFO [2022-10-23 15:35:49,939] ({SchedulerFactory7} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 62:  WARN [2022-10-23 15:38:37,526] ({SchedulerFactory3} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 63:  INFO [2022-10-23 15:38:37,569] ({SchedulerFactory3} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 64:  WARN [2022-10-23 15:40:22,501] ({SchedulerFactory8} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 65:  INFO [2022-10-23 15:40:22,554] ({SchedulerFactory8} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 66:  WARN [2022-10-23 15:40:37,143] ({SchedulerFactory5} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 67:  INFO [2022-10-23 15:40:37,211] ({SchedulerFactory5} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 68:  WARN [2022-10-23 15:41:29,744] ({SchedulerFactory9} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 69:  INFO [2022-10-23 15:41:29,796] ({SchedulerFactory9} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 70:  WARN [2022-10-23 15:44:48,647] ({SchedulerFactory10} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 71:  INFO [2022-10-23 15:44:48,695] ({SchedulerFactory10} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 72:  WARN [2022-10-23 15:49:09,233] ({SchedulerFactory4} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 73:  INFO [2022-10-23 15:49:09,323] ({SchedulerFactory4} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 74:  WARN [2022-10-23 15:57:01,236] ({SchedulerFactory13} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 75:  INFO [2022-10-23 15:57:01,283] ({SchedulerFactory13} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 76:  WARN [2022-10-23 15:58:13,146] ({SchedulerFactory3} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 77:  INFO [2022-10-23 15:58:13,182] ({SchedulerFactory3} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 78:  WARN [2022-10-23 16:06:24,941] ({SchedulerFactory14} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 79:  INFO [2022-10-23 16:06:25,009] ({SchedulerFactory14} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 80:  WARN [2022-10-23 16:06:45,378] ({SchedulerFactory27} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_317/3142727102.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\nLinea 81:  INFO [2022-10-23 16:06:45,417] ({SchedulerFactory27} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 82:  WARN [2022-10-23 16:06:52,479] ({SchedulerFactory15} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_317/2252833500.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\nLinea 83:  INFO [2022-10-23 16:06:52,531] ({SchedulerFactory15} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 84:  WARN [2022-10-23 16:07:02,586] ({SchedulerFactory5} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_317/1235164893.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\nLinea 85:  INFO [2022-10-23 16:07:02,623] ({SchedulerFactory5} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 86:  WARN [2022-10-23 16:07:14,492] ({SchedulerFactory16} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 87:  INFO [2022-10-23 16:07:14,566] ({SchedulerFactory16} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 88:  WARN [2022-10-23 16:23:39,166] ({SchedulerFactory32} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 89:  INFO [2022-10-23 16:23:39,232] ({SchedulerFactory32} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 90:  WARN [2022-10-23 16:25:56,919] ({SchedulerFactory33} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 91:  INFO [2022-10-23 16:25:57,029] ({SchedulerFactory33} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 92:  WARN [2022-10-23 16:26:05,612] ({SchedulerFactory34} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 93:  INFO [2022-10-23 16:26:05,693] ({SchedulerFactory34} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 94:  WARN [2022-10-23 16:31:49,324] ({SchedulerFactory19} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 95:  INFO [2022-10-23 16:31:49,358] ({SchedulerFactory19} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 96:  WARN [2022-10-23 16:42:50,510] ({SchedulerFactory51} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666543345849_1432029520 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 97:  INFO [2022-10-23 16:42:50,550] ({SchedulerFactory51} AbstractScheduler.java[runJob]:154) - Job paragraph_1666543345849_1432029520 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 98:  WARN [2022-10-23 16:43:09,142] ({SchedulerFactory8} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666543345849_1432029520 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 99:  INFO [2022-10-23 16:43:09,211] ({SchedulerFactory8} AbstractScheduler.java[runJob]:154) - Job paragraph_1666543345849_1432029520 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 100:  WARN [2022-10-23 16:43:45,782] ({SchedulerFactory53} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666543345849_1432029520 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 101:  INFO [2022-10-23 16:43:45,812] ({SchedulerFactory53} AbstractScheduler.java[runJob]:154) - Job paragraph_1666543345849_1432029520 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 102:  WARN [2022-10-23 19:07:08,864] ({SchedulerFactory31} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 103:  INFO [2022-10-23 19:07:08,937] ({SchedulerFactory31} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 104:  WARN [2022-10-23 19:07:24,900] ({SchedulerFactory61} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 105:  INFO [2022-10-23 19:07:24,982] ({SchedulerFactory61} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 106:  WARN [2022-10-23 19:08:27,566] ({SchedulerFactory62} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 107:  INFO [2022-10-23 19:08:27,610] ({SchedulerFactory62} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 108:  WARN [2022-10-23 19:08:58,965] ({SchedulerFactory32} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 109:  INFO [2022-10-23 19:08:59,013] ({SchedulerFactory32} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 110:  WARN [2022-10-23 19:09:40,176] ({SchedulerFactory64} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 111:  INFO [2022-10-23 19:09:40,225] ({SchedulerFactory64} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 112:  WARN [2022-10-23 19:09:48,435] ({SchedulerFactory65} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 113:  INFO [2022-10-23 19:09:48,480] ({SchedulerFactory65} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 114:  WARN [2022-10-23 19:09:55,751] ({SchedulerFactory18} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 115:  INFO [2022-10-23 19:09:55,816] ({SchedulerFactory18} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 116:  WARN [2022-10-23 19:11:13,687] ({SchedulerFactory67} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 117:  INFO [2022-10-23 19:11:13,727] ({SchedulerFactory67} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 118:  WARN [2022-10-23 19:11:55,289] ({SchedulerFactory10} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 119:  INFO [2022-10-23 19:11:55,326] ({SchedulerFactory10} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 120:  WARN [2022-10-23 19:15:50,928] ({SchedulerFactory70} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text <console>:1: \u001b[31merror: \u001b[0millegal start of definition\nLinea 121:  INFO [2022-10-23 19:15:50,962] ({SchedulerFactory70} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 122:  WARN [2022-10-23 19:16:05,480] ({SchedulerFactory71} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 123:  INFO [2022-10-23 19:16:05,518] ({SchedulerFactory71} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 124:  WARN [2022-10-23 19:16:46,244] ({SchedulerFactory72} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 125:  INFO [2022-10-23 19:16:46,292] ({SchedulerFactory72} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 126:  WARN [2022-10-23 19:16:59,489] ({SchedulerFactory73} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 127:  INFO [2022-10-23 19:16:59,544] ({SchedulerFactory73} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 128:  WARN [2022-10-23 19:36:20,162] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 129:  INFO [2022-10-23 19:36:20,206] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 130:  WARN [2022-10-23 20:08:11,627] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 131:  INFO [2022-10-23 20:08:11,720] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 132:  WARN [2022-10-23 20:08:27,397] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 133:  INFO [2022-10-23 20:08:27,469] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 134:  WARN [2022-10-23 20:16:10,220] ({SchedulerFactory3} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 135:  INFO [2022-10-23 20:16:10,351] ({SchedulerFactory3} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 136:  WARN [2022-10-23 20:16:30,941] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 137:  INFO [2022-10-23 20:16:30,993] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 138:  WARN [2022-10-23 20:16:39,753] ({SchedulerFactory4} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 139:  INFO [2022-10-23 20:16:39,816] ({SchedulerFactory4} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 140:  WARN [2022-10-23 20:16:44,704] ({SchedulerFactory3} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 141:  INFO [2022-10-23 20:16:44,753] ({SchedulerFactory3} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 142:  WARN [2022-10-23 20:18:50,353] ({SchedulerFactory5} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 143:  INFO [2022-10-23 20:18:50,393] ({SchedulerFactory5} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 144:  WARN [2022-10-23 20:30:10,780] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 145:  INFO [2022-10-23 20:30:11,349] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 146:  WARN [2022-10-23 21:07:51,635] ({SchedulerFactory7} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 147:  INFO [2022-10-23 21:07:51,704] ({SchedulerFactory7} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 148:  WARN [2022-10-23 21:08:59,688] ({SchedulerFactory14} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 149:  INFO [2022-10-23 21:08:59,739] ({SchedulerFactory14} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 150:  WARN [2022-10-23 21:09:32,342] ({SchedulerFactory5} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 151:  INFO [2022-10-23 21:09:32,401] ({SchedulerFactory5} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 152:  WARN [2022-10-23 21:09:44,908] ({SchedulerFactory16} NotebookServer.java[onStatusChange]:1986) - Job 20201023-001957_322623490 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 153:  INFO [2022-10-23 21:09:44,974] ({SchedulerFactory16} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 154:  WARN [2022-10-23 22:32:03,564] ({SchedulerFactory10} NotebookServer.java[onStatusChange]:1986) - Job 20201023-002107_2147167260 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 155:  INFO [2022-10-23 22:32:03,620] ({SchedulerFactory10} AbstractScheduler.java[runJob]:154) - Job 20201023-002107_2147167260 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 156:  WARN [2022-10-23 22:33:27,875] ({SchedulerFactory6} NotebookServer.java[onStatusChange]:1986) - Job 20201023-002107_2147167260 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 157:  INFO [2022-10-23 22:33:27,948] ({SchedulerFactory6} AbstractScheduler.java[runJob]:154) - Job 20201023-002107_2147167260 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 158:  WARN [2022-10-23 22:34:10,556] ({SchedulerFactory11} NotebookServer.java[onStatusChange]:1986) - Job 20201023-002107_2147167260 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 159:  INFO [2022-10-23 22:34:10,613] ({SchedulerFactory11} AbstractScheduler.java[runJob]:154) - Job 20201023-002107_2147167260 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 160:  WARN [2022-10-23 22:35:20,751] ({SchedulerFactory22} NotebookServer.java[onStatusChange]:1986) - Job 20201023-002107_2147167260 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 161:  INFO [2022-10-23 22:35:20,829] ({SchedulerFactory22} AbstractScheduler.java[runJob]:154) - Job 20201023-002107_2147167260 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 162:  WARN [2022-10-23 22:35:46,136] ({SchedulerFactory24} NotebookServer.java[onStatusChange]:1986) - Job 20201023-002107_2147167260 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 163:  INFO [2022-10-23 22:35:46,204] ({SchedulerFactory24} AbstractScheduler.java[runJob]:154) - Job 20201023-002107_2147167260 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 164:  WARN [2022-10-23 22:39:46,256] ({SchedulerFactory26} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1634318082132_1416467574 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 165:  INFO [2022-10-23 22:39:46,315] ({SchedulerFactory26} AbstractScheduler.java[runJob]:154) - Job paragraph_1634318082132_1416467574 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 166:  WARN [2022-10-23 22:42:15,305] ({SchedulerFactory31} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666564853357_1901912691 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 167:  INFO [2022-10-23 22:42:15,405] ({SchedulerFactory31} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 168:  WARN [2022-10-23 23:14:46,460] ({SchedulerFactory2} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666564853357_1901912691 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 169:  INFO [2022-10-23 23:14:46,510] ({SchedulerFactory2} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 170:  WARN [2022-10-23 23:25:53,008] ({SchedulerFactory18} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666564853357_1901912691 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 171:  INFO [2022-10-23 23:25:53,069] ({SchedulerFactory18} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 172:  WARN [2022-10-23 23:29:55,245] ({SchedulerFactory11} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 173:  INFO [2022-10-23 23:29:55,309] ({SchedulerFactory11} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 174:  WARN [2022-10-23 23:31:22,539] ({SchedulerFactory21} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666564853357_1901912691 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 175:  INFO [2022-10-23 23:31:22,584] ({SchedulerFactory21} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 176:  WARN [2022-10-23 23:31:35,394] ({SchedulerFactory41} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666564853357_1901912691 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 177:  INFO [2022-10-23 23:31:35,443] ({SchedulerFactory41} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 178:  WARN [2022-10-23 23:31:48,408] ({SchedulerFactory42} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666564853357_1901912691 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 179:  INFO [2022-10-23 23:31:48,514] ({SchedulerFactory42} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 180:  WARN [2022-10-23 23:31:53,247] ({SchedulerFactory22} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666564853357_1901912691 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 181:  INFO [2022-10-23 23:31:53,302] ({SchedulerFactory22} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 182:  WARN [2022-10-23 23:32:17,045] ({SchedulerFactory44} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666564853357_1901912691 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 183:  INFO [2022-10-23 23:32:17,091] ({SchedulerFactory44} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 184:  WARN [2022-10-23 23:38:01,157] ({SchedulerFactory28} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666567983671_889308879 is finished, status: ERROR, exception: null, result: %text <console>:1: \u001b[31merror: \u001b[0m';' expected but '#' found.\nLinea 185:  INFO [2022-10-23 23:38:01,218] ({SchedulerFactory28} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 186:  WARN [2022-10-23 23:38:19,623] ({SchedulerFactory15} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666567983671_889308879 is finished, status: ERROR, exception: null, result: %text <console>:31: \u001b[31merror: \u001b[0mnot found: value lines\nLinea 187:  INFO [2022-10-23 23:38:19,670] ({SchedulerFactory15} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 188:  WARN [2022-10-23 23:39:01,429] ({SchedulerFactory5} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666567983671_889308879 is finished, status: ERROR, exception: null, result: %text <console>:31: \u001b[31merror: \u001b[0mnot found: value lines\nLinea 189:  INFO [2022-10-23 23:39:01,468] ({SchedulerFactory5} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 190:  WARN [2022-10-23 23:39:07,374] ({SchedulerFactory29} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666567983671_889308879 is finished, status: ERROR, exception: null, result: %text <console>:31: \u001b[31merror: \u001b[0mnot found: value lines\nLinea 191:  INFO [2022-10-23 23:39:07,411] ({SchedulerFactory29} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 192:  WARN [2022-10-23 23:39:13,558] ({SchedulerFactory9} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666567983671_889308879 is finished, status: ERROR, exception: null, result: %text <console>:31: \u001b[31merror: \u001b[0mnot found: value lines\nLinea 193:  INFO [2022-10-23 23:39:13,596] ({SchedulerFactory9} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 194:  WARN [2022-10-23 23:39:27,511] ({SchedulerFactory30} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666567983671_889308879 is finished, status: ERROR, exception: null, result: %text <console>:31: \u001b[31merror: \u001b[0mnot found: value lines\nLinea 195:  INFO [2022-10-23 23:39:27,553] ({SchedulerFactory30} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 196:  WARN [2022-10-23 23:39:45,622] ({SchedulerFactory16} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666567983671_889308879 is finished, status: ERROR, exception: null, result: %text <console>:31: \u001b[31merror: \u001b[0mnot found: value lines\nLinea 197:  INFO [2022-10-23 23:39:45,663] ({SchedulerFactory16} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 198:  WARN [2022-10-23 23:40:55,267] ({SchedulerFactory31} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666567983671_889308879 is finished, status: ERROR, exception: null, result: %text <console>:31: \u001b[31merror: \u001b[0mnot found: value lines\nLinea 199:  INFO [2022-10-23 23:40:55,348] ({SchedulerFactory31} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 200:  WARN [2022-10-23 23:41:14,403] ({SchedulerFactory32} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666567983671_889308879 is finished, status: ERROR, exception: null, result: %text <console>:31: \u001b[31merror: \u001b[0mnot found: value lines\nLinea 201:  INFO [2022-10-23 23:41:14,444] ({SchedulerFactory32} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 202:  WARN [2022-10-23 23:41:31,202] ({SchedulerFactory17} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666567983671_889308879 is finished, status: ERROR, exception: null, result: %text <console>:30: \u001b[31merror: \u001b[0mnot found: value lines\nLinea 203:  INFO [2022-10-23 23:41:31,261] ({SchedulerFactory17} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 204:  WARN [2022-10-23 23:42:17,623] ({SchedulerFactory64} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666567983671_889308879 is finished, status: ERROR, exception: null, result: %text <console>:30: \u001b[31merror: \u001b[0mnot found: value lines\nLinea 205:  INFO [2022-10-23 23:42:17,667] ({SchedulerFactory64} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 206:  WARN [2022-10-23 23:43:53,141] ({SchedulerFactory10} NotebookServer.java[onStatusChange]:1986) - Job 20191121-184701_1405603118 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 207:  INFO [2022-10-23 23:43:53,245] ({SchedulerFactory10} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 208:  WARN [2022-10-23 23:47:16,888] ({SchedulerFactory6} NotebookServer.java[onStatusChange]:1986) - Job 20201023-002107_2147167260 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 209:  INFO [2022-10-23 23:47:16,946] ({SchedulerFactory6} AbstractScheduler.java[runJob]:154) - Job 20201023-002107_2147167260 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\nLinea 210:  INFO [2022-10-24 00:00:57,102] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 211:  INFO [2022-10-24 00:01:10,447] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 212:  INFO [2022-10-24 00:02:09,328] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 213:  INFO [2022-10-24 00:12:28,293] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 214:  INFO [2022-10-18 13:52:22,745] ({FIFOScheduler-interpreter_621085749-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_621085749 with status ERROR\nLinea 215:  INFO [2022-10-18 13:52:43,005] ({FIFOScheduler-interpreter_621085749-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_621085749 with status ERROR\nLinea 216: ERROR [2022-10-18 14:15:20,664] ({pool-2-thread-1} RemoteInterpreterServer.java[shutdown]:248) - Fail to unregister remote interpreter process\nLinea 217: ERROR [2022-10-18 14:15:20,664] ({ShutdownThread} RemoteInterpreterServer.java[run]:682) - Fail to unregister remote interpreter process\nLinea 218: ERROR [2022-10-18 14:15:20,672] ({pool-2-thread-1} ProcessFunction.java[process]:47) - Internal error processing shutdown\nLinea 219:  INFO [2022-10-18 14:54:37,231] ({FIFOScheduler-interpreter_418030203-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_418030203 with status ERROR\nLinea 220:  INFO [2022-10-18 14:58:44,290] ({FIFOScheduler-interpreter_418030203-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_418030203 with status ERROR\nLinea 221:  INFO [2022-10-18 14:59:01,300] ({FIFOScheduler-interpreter_418030203-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_418030203 with status ERROR\nLinea 222:  INFO [2022-10-18 15:01:08,526] ({FIFOScheduler-interpreter_418030203-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_418030203 with status ERROR\nLinea 223:  INFO [2022-10-18 15:01:14,749] ({FIFOScheduler-interpreter_418030203-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_418030203 with status ERROR\nLinea 224:  INFO [2022-10-18 15:01:22,994] ({FIFOScheduler-interpreter_418030203-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_418030203 with status ERROR\nLinea 225:  INFO [2022-10-18 15:04:09,172] ({FIFOScheduler-interpreter_418030203-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_418030203 with status ERROR\nLinea 226:  INFO [2022-10-18 15:05:44,334] ({FIFOScheduler-interpreter_418030203-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_418030203 with status ERROR\nLinea 227:  INFO [2022-10-18 15:06:07,053] ({FIFOScheduler-interpreter_418030203-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_418030203 with status ERROR\nLinea 228:  INFO [2022-10-19 14:30:52,097] ({FIFOScheduler-interpreter_275524707-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_275524707 with status ERROR\nLinea 229:  INFO [2022-10-19 14:39:38,047] ({FIFOScheduler-interpreter_275524707-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_275524707 with status ERROR\nLinea 230:  INFO [2022-10-19 14:40:28,551] ({FIFOScheduler-interpreter_275524707-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_275524707 with status ERROR\nLinea 231:  INFO [2022-10-19 14:40:38,251] ({FIFOScheduler-interpreter_275524707-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_275524707 with status ERROR\nLinea 232:  INFO [2022-10-19 14:41:34,750] ({FIFOScheduler-interpreter_275524707-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_275524707 with status ERROR\nLinea 233:  INFO [2022-10-19 14:41:51,695] ({FIFOScheduler-interpreter_275524707-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_275524707 with status ERROR\nLinea 234:  INFO [2022-10-19 14:41:57,186] ({FIFOScheduler-interpreter_275524707-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_275524707 with status ERROR\nLinea 235:  INFO [2022-10-19 14:42:31,022] ({FIFOScheduler-interpreter_275524707-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666100897380_1473405501 finished by scheduler interpreter_275524707 with status ERROR\nLinea 236:  INFO [2022-10-23 15:31:40,461] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 237:  INFO [2022-10-23 15:31:57,113] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 238:  INFO [2022-10-23 15:33:07,657] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 239:  INFO [2022-10-23 15:33:31,045] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 240:  INFO [2022-10-23 15:33:52,377] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 241:  INFO [2022-10-23 15:34:09,691] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 242:  INFO [2022-10-23 15:35:08,953] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 243:  INFO [2022-10-23 15:35:49,874] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 244:  INFO [2022-10-23 15:38:37,523] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 245:  INFO [2022-10-23 15:40:22,499] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 246:  INFO [2022-10-23 15:40:37,140] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 247:  INFO [2022-10-23 15:41:29,742] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 248:  INFO [2022-10-23 15:44:48,644] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 249: ERROR [2022-10-23 15:49:08,919] ({Executor task launch worker for task 140} Logging.scala[logError]:91) - Exception in task 0.0 in stage 42.0 (TID 140)\nLinea 250: ERROR [2022-10-23 15:49:08,919] ({Executor task launch worker for task 141} Logging.scala[logError]:91) - Exception in task 1.0 in stage 42.0 (TID 141)\nLinea 251: ERROR [2022-10-23 15:49:09,055] ({task-result-getter-0} Logging.scala[logError]:70) - Task 0 in stage 42.0 failed 1 times; aborting job\nLinea 252:  INFO [2022-10-23 15:49:09,225] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 253:  INFO [2022-10-23 15:57:01,234] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 254:  INFO [2022-10-23 15:58:13,144] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 255: ERROR [2022-10-23 16:06:24,746] ({Executor task launch worker for task 163} Logging.scala[logError]:91) - Exception in task 1.0 in stage 58.0 (TID 163)\nLinea 256: ERROR [2022-10-23 16:06:24,747] ({Executor task launch worker for task 162} Logging.scala[logError]:91) - Exception in task 0.0 in stage 58.0 (TID 162)\nLinea 257: ERROR [2022-10-23 16:06:24,757] ({task-result-getter-1} Logging.scala[logError]:70) - Task 0 in stage 58.0 failed 1 times; aborting job\nLinea 258:  INFO [2022-10-23 16:06:24,929] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 259:  INFO [2022-10-23 16:06:45,377] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 260:  INFO [2022-10-23 16:06:52,476] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 261:  INFO [2022-10-23 16:07:02,585] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 262: ERROR [2022-10-23 16:07:14,229] ({Executor task launch worker for task 165} Logging.scala[logError]:91) - Exception in task 1.0 in stage 60.0 (TID 165)\nLinea 263: ERROR [2022-10-23 16:07:14,249] ({Executor task launch worker for task 164} Logging.scala[logError]:91) - Exception in task 0.0 in stage 60.0 (TID 164)\nLinea 264: ERROR [2022-10-23 16:07:14,256] ({task-result-getter-0} Logging.scala[logError]:70) - Task 1 in stage 60.0 failed 1 times; aborting job\nLinea 265:  INFO [2022-10-23 16:07:14,482] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 266: ERROR [2022-10-23 16:23:38,855] ({Executor task launch worker for task 177} Logging.scala[logError]:91) - Exception in task 1.0 in stage 69.0 (TID 177)\nLinea 267: ERROR [2022-10-23 16:23:38,861] ({task-result-getter-0} Logging.scala[logError]:70) - Task 1 in stage 69.0 failed 1 times; aborting job\nLinea 268:  INFO [2022-10-23 16:23:39,158] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 269: ERROR [2022-10-23 16:25:56,746] ({Executor task launch worker for task 179} Logging.scala[logError]:91) - Exception in task 1.0 in stage 71.0 (TID 179)\nLinea 270: ERROR [2022-10-23 16:25:56,752] ({task-result-getter-1} Logging.scala[logError]:70) - Task 1 in stage 71.0 failed 1 times; aborting job\nLinea 271: ERROR [2022-10-23 16:25:56,759] ({Executor task launch worker for task 178} Logging.scala[logError]:91) - Exception in task 0.0 in stage 71.0 (TID 178)\nLinea 272:  INFO [2022-10-23 16:25:56,910] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 273: ERROR [2022-10-23 16:26:05,440] ({Executor task launch worker for task 180} Logging.scala[logError]:91) - Exception in task 0.0 in stage 73.0 (TID 180)\nLinea 274: ERROR [2022-10-23 16:26:05,447] ({task-result-getter-0} Logging.scala[logError]:70) - Task 0 in stage 73.0 failed 1 times; aborting job\nLinea 275: ERROR [2022-10-23 16:26:05,447] ({Executor task launch worker for task 181} Logging.scala[logError]:91) - Exception in task 1.0 in stage 73.0 (TID 181)\nLinea 276:  INFO [2022-10-23 16:26:05,604] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 277: ERROR [2022-10-23 16:31:49,188] ({Executor task launch worker for task 192} Logging.scala[logError]:91) - Exception in task 0.0 in stage 82.0 (TID 192)\nLinea 278: ERROR [2022-10-23 16:31:49,191] ({task-result-getter-0} Logging.scala[logError]:70) - Task 0 in stage 82.0 failed 1 times; aborting job\nLinea 279: ERROR [2022-10-23 16:31:49,193] ({Executor task launch worker for task 193} Logging.scala[logError]:91) - Exception in task 1.0 in stage 82.0 (TID 193)\nLinea 280:  INFO [2022-10-23 16:31:49,319] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 281:  INFO [2022-10-23 16:42:50,507] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666543345849_1432029520 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 282:  INFO [2022-10-23 16:43:09,138] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666543345849_1432029520 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 283:  INFO [2022-10-23 16:43:45,780] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666543345849_1432029520 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 284:  INFO [2022-10-23 19:07:08,853] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 285:  INFO [2022-10-23 19:07:24,896] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 286:  INFO [2022-10-23 19:08:27,562] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 287:  INFO [2022-10-23 19:08:58,962] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 288:  INFO [2022-10-23 19:09:40,171] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 289:  INFO [2022-10-23 19:09:48,432] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 290:  INFO [2022-10-23 19:09:55,746] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 291:  INFO [2022-10-23 19:11:13,684] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 292:  INFO [2022-10-23 19:11:55,285] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 293:  INFO [2022-10-23 19:15:50,925] ({FIFOScheduler-interpreter_770107601-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_770107601 with status ERROR\nLinea 294:  INFO [2022-10-23 19:16:05,477] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 295:  INFO [2022-10-23 19:16:46,240] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 296:  INFO [2022-10-23 19:16:59,484] ({FIFOScheduler-interpreter_1732968916-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1732968916 with status ERROR\nLinea 297:  INFO [2022-10-23 19:36:20,097] ({FIFOScheduler-interpreter_1584798927-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1584798927 with status ERROR\nLinea 298: ERROR [2022-10-23 20:03:08,290] ({pool-2-thread-1} ProcessFunction.java[process]:47) - Internal error processing shutdown\nLinea 299: ERROR [2022-10-23 20:03:08,307] ({pool-2-thread-2} ProcessFunction.java[process]:47) - Internal error processing shutdown\nLinea 300:  INFO [2022-10-23 20:08:11,556] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 301:  INFO [2022-10-23 20:08:27,390] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 302:  INFO [2022-10-23 20:16:10,211] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 303:  INFO [2022-10-23 20:16:30,938] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 304:  INFO [2022-10-23 20:16:39,751] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 305:  INFO [2022-10-23 20:16:44,702] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 306:  INFO [2022-10-23 20:18:50,350] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 307:  INFO [2022-10-23 20:30:10,777] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 308:  INFO [2022-10-23 21:07:51,627] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 309:  INFO [2022-10-23 21:08:59,683] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 310:  INFO [2022-10-23 21:09:32,338] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 311:  INFO [2022-10-23 21:09:44,904] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-001957_322623490 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 312:  INFO [2022-10-23 22:32:03,550] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-002107_2147167260 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 313:  INFO [2022-10-23 22:33:27,869] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-002107_2147167260 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 314:  INFO [2022-10-23 22:34:10,551] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-002107_2147167260 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 315:  INFO [2022-10-23 22:35:20,746] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-002107_2147167260 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 316:  INFO [2022-10-23 22:35:46,134] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-002107_2147167260 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 317:  INFO [2022-10-23 22:39:46,255] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1634318082132_1416467574 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 318:  INFO [2022-10-23 22:42:15,299] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 319:  INFO [2022-10-23 23:14:46,451] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 320:  INFO [2022-10-23 23:25:53,001] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 321: ERROR [2022-10-23 23:29:54,931] ({Executor task launch worker for task 374} Logging.scala[logError]:91) - Exception in task 1.0 in stage 48.0 (TID 374)\nLinea 322: ERROR [2022-10-23 23:29:54,931] ({Executor task launch worker for task 373} Logging.scala[logError]:91) - Exception in task 0.0 in stage 48.0 (TID 373)\nLinea 323: ERROR [2022-10-23 23:29:55,041] ({task-result-getter-2} Logging.scala[logError]:70) - Task 1 in stage 48.0 failed 1 times; aborting job\nLinea 324:  INFO [2022-10-23 23:29:55,237] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 325:  INFO [2022-10-23 23:31:22,535] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 326:  INFO [2022-10-23 23:31:35,390] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 327:  INFO [2022-10-23 23:31:48,403] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 328:  INFO [2022-10-23 23:31:53,242] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 329:  INFO [2022-10-23 23:32:17,041] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 330:  INFO [2022-10-23 23:38:01,155] ({FIFOScheduler-interpreter_688378262-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler interpreter_688378262 with status ERROR\nLinea 331:  INFO [2022-10-23 23:38:19,620] ({FIFOScheduler-interpreter_688378262-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler interpreter_688378262 with status ERROR\nLinea 332:  INFO [2022-10-23 23:39:01,427] ({FIFOScheduler-interpreter_688378262-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler interpreter_688378262 with status ERROR\nLinea 333:  INFO [2022-10-23 23:39:07,373] ({FIFOScheduler-interpreter_688378262-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler interpreter_688378262 with status ERROR\nLinea 334:  INFO [2022-10-23 23:39:13,556] ({FIFOScheduler-interpreter_688378262-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler interpreter_688378262 with status ERROR\nLinea 335:  INFO [2022-10-23 23:39:27,509] ({FIFOScheduler-interpreter_688378262-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler interpreter_688378262 with status ERROR\nLinea 336:  INFO [2022-10-23 23:39:45,620] ({FIFOScheduler-interpreter_688378262-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler interpreter_688378262 with status ERROR\nLinea 337:  INFO [2022-10-23 23:40:55,260] ({FIFOScheduler-interpreter_688378262-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler interpreter_688378262 with status ERROR\nLinea 338:  INFO [2022-10-23 23:41:14,402] ({FIFOScheduler-interpreter_688378262-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler interpreter_688378262 with status ERROR\nLinea 339:  INFO [2022-10-23 23:41:31,200] ({FIFOScheduler-interpreter_688378262-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler interpreter_688378262 with status ERROR\nLinea 340:  INFO [2022-10-23 23:42:17,623] ({FIFOScheduler-interpreter_688378262-Worker-1} AbstractScheduler.java[runJob]:154) - Job paragraph_1666567983671_889308879 finished by scheduler interpreter_688378262 with status ERROR\nLinea 341: ERROR [2022-10-23 23:43:52,895] ({Executor task launch worker for task 383} Logging.scala[logError]:91) - Exception in task 1.0 in stage 57.0 (TID 383)\nLinea 342: ERROR [2022-10-23 23:43:52,897] ({Executor task launch worker for task 382} Logging.scala[logError]:91) - Exception in task 0.0 in stage 57.0 (TID 382)\nLinea 343: ERROR [2022-10-23 23:43:52,924] ({task-result-getter-0} Logging.scala[logError]:70) - Task 1 in stage 57.0 failed 1 times; aborting job\nLinea 344:  INFO [2022-10-23 23:43:53,131] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20191121-184701_1405603118 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 345:  INFO [2022-10-23 23:47:16,884] ({FIFOScheduler-interpreter_1798444030-Worker-1} AbstractScheduler.java[runJob]:154) - Job 20201023-002107_2147167260 finished by scheduler interpreter_1798444030 with status ERROR\nLinea 346:  WARN [2022-10-15 13:08:28,465] ({main} ZeppelinConfiguration.java[<init>]:85) - Failed to load XML configuration, proceeding with a default,for a stacktrace activate the debug log\nLinea 347:  WARN [2022-10-15 13:08:29,002] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 348:  WARN [2022-10-15 13:08:29,003] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 349:  WARN [2022-10-15 13:08:29,003] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 350:  WARN [2022-10-16 21:42:36,480] ({main} ZeppelinConfiguration.java[<init>]:85) - Failed to load XML configuration, proceeding with a default,for a stacktrace activate the debug log\nLinea 351:  WARN [2022-10-16 21:42:37,037] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 352:  WARN [2022-10-16 21:42:37,038] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 353:  WARN [2022-10-16 21:42:37,038] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 354:  WARN [2022-10-18 11:46:15,416] ({main} ZeppelinConfiguration.java[<init>]:85) - Failed to load XML configuration, proceeding with a default,for a stacktrace activate the debug log\nLinea 355:  WARN [2022-10-18 11:46:20,221] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 356:  WARN [2022-10-18 11:46:20,227] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 357:  WARN [2022-10-18 11:46:20,228] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 358:  INFO [2022-10-18 13:44:21,355] ({SchedulerFactory2} SparkInterpreterLauncher.java[buildEnvFromProperties]:245) - buildEnvFromProperties: {PATH=/opt/conda/envs/python_3_with_R/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin, ZEPPELIN_LOG_DIR=/opt/zeppelin/logs, ZEPPELIN_WAR=/opt/zeppelin/zeppelin-web-0.10.0.war, ZEPPELIN_ENCODING=UTF-8, ZEPPELIN_SPARK_CONF=--conf|spark.executor.instances=2|--conf|spark.sql.catalogImplementation=hive|--conf|spark.app.name=spark-shared_process|--conf|spark.webui.yarn.useProxy=false|--conf|spark.driver.cores=1|--conf|spark.executor.memory=1g|--conf|spark.master=local[*]|--conf|spark.jars.packages=graphframes:graphframes:0.6.0-spark2.2-s_2.11|--conf|spark.driver.memory=1g|--conf|spark.executor.cores=1, JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64, JAVA_OPTS=  -Dfile.encoding=UTF-8 -Xmx1024m -Dlog4j.configuration=file:///opt/zeppelin/conf/log4j.properties -Dzeppelin.log.file=/opt/zeppelin/logs/zeppelin--localhost.log, TERM=screen, INTERPRETER_GROUP_ID=spark-shared_process, S_VERSION=2.4.8, Z_VERSION=0.10.0, LANG=en_US.UTF-8, JAVA_INTP_OPTS= -Dfile.encoding=UTF-8 -Dlog4j.configuration=file:///opt/zeppelin/conf/log4j.properties -Dlog4j.configurationFile=file:///opt/zeppelin/conf/log4j2.properties, PYSPARK_PYTHON=python, SPARK_HOME=/opt/spark, ZEPPELIN_CONF_DIR=/opt/zeppelin/conf, ZEPPELIN_NOTEBOOK_DIR=/notebook, STY=11.pts-0.localhost, ZEPPELIN_RUNNER=/usr/lib/jvm/java-8-openjdk-amd64/bin/java, PWD=/opt/zeppelin, ZEPPELIN_HOME=/opt/zeppelin, LOG_TAG=[ZEPPELIN_0.10.0]:, SHELL=/bin/bash, ZEPPELIN_INTP_MEM=-Xmx1024m, PYSPARK_DRIVER_PYTHON=python, ZEPPELIN_PID_DIR=/opt/zeppelin/run, ZEPPELIN_ANGULAR_WAR=/opt/zeppelin/zeppelin-web-angular-0.10.0.war, WINDOW=0, ZEPPELIN_MEM=-Xmx1024m, ZEPPELIN_INTERPRETER_CONNECT_TIMEOUT=120000, HOSTNAME=localhost, LC_ALL=en_US.UTF-8, ZEPPELIN_IDENT_STRING=, PYSPARK_PIN_THREAD=true, TERMCAP=SC|screen|VT 100/ANSI X3.64 virtual terminal:DO=\\E[%dB:LE=\\E[%dD:RI=\\E[%dC:UP=\\E[%dA:bs:bt=\\E[Z:cd=\\E[J:ce=\\E[K:cl=\\E[H\\E[J:cm=\\E[%i%d;%dH:ct=\\E[3g:do=^J:nd=\\E[C:pt:rc=\\E8:rs=\\Ec:sc=\\E7:st=\\EH:up=\\EM:le=^H:bl=^G:cr=^M:it#8:ho=\\E[H:nw=\\EE:ta=^I:is=\\E)0:li#13:co#137:am:xn:xv:LP:sr=\\EM:al=\\E[L:AL=\\E[%dL:cs=\\E[%i%d;%dr:dl=\\E[M:DL=\\E[%dM:dc=\\E[P:DC=\\E[%dP:im=\\E[4h:ei=\\E[4l:mi:IC=\\E[%d@:ks=\\E[?1h\\E=:ke=\\E[?1l\\E>:vi=\\E[?25l:ve=\\E[34h\\E[?25h:vs=\\E[34l:ti=\\E[?1049h:te=\\E[?1049l:us=\\E[4m:ue=\\E[24m:so=\\E[3m:se=\\E[23m:mb=\\E[5m:md=\\E[1m:mh=\\E[2m:mr=\\E[7m:me=\\E[m:ms:Co#8:pa#64:AF=\\E[3%dm:AB=\\E[4%dm:op=\\E[39;49m:AX:vb=\\Eg:G0:as=\\E(0:ae=\\E(B:ac=\\140\\140aaffggjjkkllmmnnooppqqrrssttuuvvwwxxyyzz{{||}}~~..--++,,hhII00:po=\\E[5i:pf=\\E[4i:Km=\\E[M:k0=\\E[10~:k1=\\EOP:k2=\\EOQ:k3=\\EOR:k4=\\EOS:k5=\\E[15~:k6=\\E[17~:k7=\\E[18~:k8=\\E[19~:k9=\\E[20~:k;=\\E[21~:F1=\\E[23~:F2=\\E[24~:kB=\\E[Z:kh=\\E[1~:@1=\\E[1~:kH=\\E[4~:@7=\\E[4~:kN=\\E[6~:kP=\\E[5~:kI=\\E[2~:kD=\\E[3~:ku=\\EOA:kd=\\EOB:kr=\\EOC:kl=\\EOD:km:, ZEPPELIN_ADDR=0.0.0.0, ZEPPELIN_INTERPRETER_REMOTE_RUNNER=bin/interpreter.sh, SHLVL=0, HOME=/opt/zeppelin}\nLinea 359:  INFO [2022-10-18 13:44:23,969] ({Exec Stream Pumper} ProcessLauncher.java[processLine]:189) - [INFO] Interpreter launch command: /opt/spark/bin/spark-submit --class org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer --driver-class-path :/opt/zeppelin/local-repo/spark/*:/opt/zeppelin/interpreter/spark/*:::/opt/zeppelin/interpreter/zeppelin-interpreter-shaded-0.10.0.jar:/opt/zeppelin/interpreter/spark/spark-interpreter-0.10.0.jar --driver-java-options  -Dfile.encoding=UTF-8 -Dlog4j.configuration=file:///opt/zeppelin/conf/log4j.properties -Dlog4j.configurationFile=file:///opt/zeppelin/conf/log4j2.properties -Dzeppelin.log.file=/opt/zeppelin/logs/zeppelin-interpreter-spark-shared_process--localhost.log --conf spark.executor.instances=2 --conf spark.sql.catalogImplementation=hive --conf spark.app.name=spark-shared_process --conf spark.webui.yarn.useProxy=false --conf spark.driver.cores=1 --conf spark.executor.memory=1g --conf spark.master=local[*] --conf spark.jars.packages=graphframes:graphframes:0.6.0-spark2.2-s_2.11 --conf spark.driver.memory=1g --conf spark.executor.cores=1 /opt/zeppelin/interpreter/spark/spark-interpreter-0.10.0.jar 172.17.0.2 45665 spark-shared_process :\nLinea 360:  WARN [2022-10-18 14:52:51,705] ({main} ZeppelinConfiguration.java[<init>]:85) - Failed to load XML configuration, proceeding with a default,for a stacktrace activate the debug log\nLinea 361:  WARN [2022-10-18 14:52:52,900] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 362:  WARN [2022-10-18 14:52:52,901] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 363:  WARN [2022-10-18 14:52:52,903] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 364:  INFO [2022-10-18 14:53:31,415] ({SchedulerFactory2} SparkInterpreterLauncher.java[buildEnvFromProperties]:245) - buildEnvFromProperties: {PATH=/opt/conda/envs/python_3_with_R/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin, ZEPPELIN_LOG_DIR=/opt/zeppelin/logs, ZEPPELIN_WAR=/opt/zeppelin/zeppelin-web-0.10.0.war, ZEPPELIN_ENCODING=UTF-8, ZEPPELIN_SPARK_CONF=--conf|spark.executor.instances=2|--conf|spark.sql.catalogImplementation=hive|--conf|spark.app.name=spark-shared_process|--conf|spark.webui.yarn.useProxy=false|--conf|spark.driver.cores=1|--conf|spark.executor.memory=1g|--conf|spark.master=local[*]|--conf|spark.jars.packages=graphframes:graphframes:0.6.0-spark2.2-s_2.11|--conf|spark.driver.memory=1g|--conf|spark.executor.cores=1, JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64, JAVA_OPTS=  -Dfile.encoding=UTF-8 -Xmx1024m -Dlog4j.configuration=file:///opt/zeppelin/conf/log4j.properties -Dzeppelin.log.file=/opt/zeppelin/logs/zeppelin--localhost.log, TERM=screen, INTERPRETER_GROUP_ID=spark-shared_process, S_VERSION=2.4.8, Z_VERSION=0.10.0, LANG=en_US.UTF-8, JAVA_INTP_OPTS= -Dfile.encoding=UTF-8 -Dlog4j.configuration=file:///opt/zeppelin/conf/log4j.properties -Dlog4j.configurationFile=file:///opt/zeppelin/conf/log4j2.properties, PYSPARK_PYTHON=python, SPARK_HOME=/opt/spark, ZEPPELIN_CONF_DIR=/opt/zeppelin/conf, ZEPPELIN_NOTEBOOK_DIR=/notebook, STY=11.pts-0.localhost, ZEPPELIN_RUNNER=/usr/lib/jvm/java-8-openjdk-amd64/bin/java, PWD=/opt/zeppelin, ZEPPELIN_HOME=/opt/zeppelin, LOG_TAG=[ZEPPELIN_0.10.0]:, SHELL=/bin/bash, ZEPPELIN_INTP_MEM=-Xmx1024m, PYSPARK_DRIVER_PYTHON=python, ZEPPELIN_PID_DIR=/opt/zeppelin/run, ZEPPELIN_ANGULAR_WAR=/opt/zeppelin/zeppelin-web-angular-0.10.0.war, WINDOW=0, ZEPPELIN_MEM=-Xmx1024m, ZEPPELIN_INTERPRETER_CONNECT_TIMEOUT=120000, HOSTNAME=localhost, LC_ALL=en_US.UTF-8, ZEPPELIN_IDENT_STRING=, PYSPARK_PIN_THREAD=true, TERMCAP=SC|screen|VT 100/ANSI X3.64 virtual terminal:DO=\\E[%dB:LE=\\E[%dD:RI=\\E[%dC:UP=\\E[%dA:bs:bt=\\E[Z:cd=\\E[J:ce=\\E[K:cl=\\E[H\\E[J:cm=\\E[%i%d;%dH:ct=\\E[3g:do=^J:nd=\\E[C:pt:rc=\\E8:rs=\\Ec:sc=\\E7:st=\\EH:up=\\EM:le=^H:bl=^G:cr=^M:it#8:ho=\\E[H:nw=\\EE:ta=^I:is=\\E)0:li#13:co#137:am:xn:xv:LP:sr=\\EM:al=\\E[L:AL=\\E[%dL:cs=\\E[%i%d;%dr:dl=\\E[M:DL=\\E[%dM:dc=\\E[P:DC=\\E[%dP:im=\\E[4h:ei=\\E[4l:mi:IC=\\E[%d@:ks=\\E[?1h\\E=:ke=\\E[?1l\\E>:vi=\\E[?25l:ve=\\E[34h\\E[?25h:vs=\\E[34l:ti=\\E[?1049h:te=\\E[?1049l:us=\\E[4m:ue=\\E[24m:so=\\E[3m:se=\\E[23m:mb=\\E[5m:md=\\E[1m:mh=\\E[2m:mr=\\E[7m:me=\\E[m:ms:Co#8:pa#64:AF=\\E[3%dm:AB=\\E[4%dm:op=\\E[39;49m:AX:vb=\\Eg:G0:as=\\E(0:ae=\\E(B:ac=\\140\\140aaffggjjkkllmmnnooppqqrrssttuuvvwwxxyyzz{{||}}~~..--++,,hhII00:po=\\E[5i:pf=\\E[4i:Km=\\E[M:k0=\\E[10~:k1=\\EOP:k2=\\EOQ:k3=\\EOR:k4=\\EOS:k5=\\E[15~:k6=\\E[17~:k7=\\E[18~:k8=\\E[19~:k9=\\E[20~:k;=\\E[21~:F1=\\E[23~:F2=\\E[24~:kB=\\E[Z:kh=\\E[1~:@1=\\E[1~:kH=\\E[4~:@7=\\E[4~:kN=\\E[6~:kP=\\E[5~:kI=\\E[2~:kD=\\E[3~:ku=\\EOA:kd=\\EOB:kr=\\EOC:kl=\\EOD:km:, ZEPPELIN_ADDR=0.0.0.0, ZEPPELIN_INTERPRETER_REMOTE_RUNNER=bin/interpreter.sh, SHLVL=0, HOME=/opt/zeppelin}\nLinea 365:  INFO [2022-10-18 14:53:32,841] ({Exec Stream Pumper} ProcessLauncher.java[processLine]:189) - [INFO] Interpreter launch command: /opt/spark/bin/spark-submit --class org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer --driver-class-path :/opt/zeppelin/local-repo/spark/*:/opt/zeppelin/interpreter/spark/*:::/opt/zeppelin/interpreter/zeppelin-interpreter-shaded-0.10.0.jar:/opt/zeppelin/interpreter/spark/spark-interpreter-0.10.0.jar --driver-java-options  -Dfile.encoding=UTF-8 -Dlog4j.configuration=file:///opt/zeppelin/conf/log4j.properties -Dlog4j.configurationFile=file:///opt/zeppelin/conf/log4j2.properties -Dzeppelin.log.file=/opt/zeppelin/logs/zeppelin-interpreter-spark-shared_process--localhost.log --conf spark.executor.instances=2 --conf spark.sql.catalogImplementation=hive --conf spark.app.name=spark-shared_process --conf spark.webui.yarn.useProxy=false --conf spark.driver.cores=1 --conf spark.executor.memory=1g --conf spark.master=local[*] --conf spark.jars.packages=graphframes:graphframes:0.6.0-spark2.2-s_2.11 --conf spark.driver.memory=1g --conf spark.executor.cores=1 /opt/zeppelin/interpreter/spark/spark-interpreter-0.10.0.jar 172.17.0.2 46023 spark-shared_process :\nLinea 366:  WARN [2022-10-19 14:23:33,388] ({main} ZeppelinConfiguration.java[<init>]:85) - Failed to load XML configuration, proceeding with a default,for a stacktrace activate the debug log\nLinea 367:  WARN [2022-10-19 14:23:34,207] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 368:  WARN [2022-10-19 14:23:34,208] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 369:  WARN [2022-10-19 14:23:34,209] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 370:  INFO [2022-10-19 14:30:01,397] ({SchedulerFactory2} SparkInterpreterLauncher.java[buildEnvFromProperties]:245) - buildEnvFromProperties: {PATH=/opt/conda/envs/python_3_with_R/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin, ZEPPELIN_LOG_DIR=/opt/zeppelin/logs, ZEPPELIN_WAR=/opt/zeppelin/zeppelin-web-0.10.0.war, ZEPPELIN_ENCODING=UTF-8, ZEPPELIN_SPARK_CONF=--conf|spark.executor.instances=2|--conf|spark.sql.catalogImplementation=hive|--conf|spark.app.name=spark-shared_process|--conf|spark.webui.yarn.useProxy=false|--conf|spark.driver.cores=1|--conf|spark.executor.memory=1g|--conf|spark.master=local[*]|--conf|spark.jars.packages=graphframes:graphframes:0.6.0-spark2.2-s_2.11|--conf|spark.driver.memory=1g|--conf|spark.executor.cores=1, JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64, JAVA_OPTS=  -Dfile.encoding=UTF-8 -Xmx1024m -Dlog4j.configuration=file:///opt/zeppelin/conf/log4j.properties -Dzeppelin.log.file=/opt/zeppelin/logs/zeppelin--localhost.log, TERM=screen, INTERPRETER_GROUP_ID=spark-shared_process, S_VERSION=2.4.8, Z_VERSION=0.10.0, LANG=en_US.UTF-8, JAVA_INTP_OPTS= -Dfile.encoding=UTF-8 -Dlog4j.configuration=file:///opt/zeppelin/conf/log4j.properties -Dlog4j.configurationFile=file:///opt/zeppelin/conf/log4j2.properties, PYSPARK_PYTHON=python, SPARK_HOME=/opt/spark, ZEPPELIN_CONF_DIR=/opt/zeppelin/conf, ZEPPELIN_NOTEBOOK_DIR=/notebook, STY=11.pts-0.localhost, ZEPPELIN_RUNNER=/usr/lib/jvm/java-8-openjdk-amd64/bin/java, PWD=/opt/zeppelin, ZEPPELIN_HOME=/opt/zeppelin, LOG_TAG=[ZEPPELIN_0.10.0]:, SHELL=/bin/bash, ZEPPELIN_INTP_MEM=-Xmx1024m, PYSPARK_DRIVER_PYTHON=python, ZEPPELIN_PID_DIR=/opt/zeppelin/run, ZEPPELIN_ANGULAR_WAR=/opt/zeppelin/zeppelin-web-angular-0.10.0.war, WINDOW=0, ZEPPELIN_MEM=-Xmx1024m, ZEPPELIN_INTERPRETER_CONNECT_TIMEOUT=120000, HOSTNAME=localhost, LC_ALL=en_US.UTF-8, ZEPPELIN_IDENT_STRING=, PYSPARK_PIN_THREAD=true, TERMCAP=SC|screen|VT 100/ANSI X3.64 virtual terminal:DO=\\E[%dB:LE=\\E[%dD:RI=\\E[%dC:UP=\\E[%dA:bs:bt=\\E[Z:cd=\\E[J:ce=\\E[K:cl=\\E[H\\E[J:cm=\\E[%i%d;%dH:ct=\\E[3g:do=^J:nd=\\E[C:pt:rc=\\E8:rs=\\Ec:sc=\\E7:st=\\EH:up=\\EM:le=^H:bl=^G:cr=^M:it#8:ho=\\E[H:nw=\\EE:ta=^I:is=\\E)0:li#13:co#137:am:xn:xv:LP:sr=\\EM:al=\\E[L:AL=\\E[%dL:cs=\\E[%i%d;%dr:dl=\\E[M:DL=\\E[%dM:dc=\\E[P:DC=\\E[%dP:im=\\E[4h:ei=\\E[4l:mi:IC=\\E[%d@:ks=\\E[?1h\\E=:ke=\\E[?1l\\E>:vi=\\E[?25l:ve=\\E[34h\\E[?25h:vs=\\E[34l:ti=\\E[?1049h:te=\\E[?1049l:us=\\E[4m:ue=\\E[24m:so=\\E[3m:se=\\E[23m:mb=\\E[5m:md=\\E[1m:mh=\\E[2m:mr=\\E[7m:me=\\E[m:ms:Co#8:pa#64:AF=\\E[3%dm:AB=\\E[4%dm:op=\\E[39;49m:AX:vb=\\Eg:G0:as=\\E(0:ae=\\E(B:ac=\\140\\140aaffggjjkkllmmnnooppqqrrssttuuvvwwxxyyzz{{||}}~~..--++,,hhII00:po=\\E[5i:pf=\\E[4i:Km=\\E[M:k0=\\E[10~:k1=\\EOP:k2=\\EOQ:k3=\\EOR:k4=\\EOS:k5=\\E[15~:k6=\\E[17~:k7=\\E[18~:k8=\\E[19~:k9=\\E[20~:k;=\\E[21~:F1=\\E[23~:F2=\\E[24~:kB=\\E[Z:kh=\\E[1~:@1=\\E[1~:kH=\\E[4~:@7=\\E[4~:kN=\\E[6~:kP=\\E[5~:kI=\\E[2~:kD=\\E[3~:ku=\\EOA:kd=\\EOB:kr=\\EOC:kl=\\EOD:km:, ZEPPELIN_ADDR=0.0.0.0, ZEPPELIN_INTERPRETER_REMOTE_RUNNER=bin/interpreter.sh, SHLVL=0, HOME=/opt/zeppelin}\nLinea 371:  INFO [2022-10-19 14:30:02,839] ({Exec Stream Pumper} ProcessLauncher.java[processLine]:189) - [INFO] Interpreter launch command: /opt/spark/bin/spark-submit --class org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer --driver-class-path :/opt/zeppelin/local-repo/spark/*:/opt/zeppelin/interpreter/spark/*:::/opt/zeppelin/interpreter/zeppelin-interpreter-shaded-0.10.0.jar:/opt/zeppelin/interpreter/spark/spark-interpreter-0.10.0.jar --driver-java-options  -Dfile.encoding=UTF-8 -Dlog4j.configuration=file:///opt/zeppelin/conf/log4j.properties -Dlog4j.configurationFile=file:///opt/zeppelin/conf/log4j2.properties -Dzeppelin.log.file=/opt/zeppelin/logs/zeppelin-interpreter-spark-shared_process--localhost.log --conf spark.executor.instances=2 --conf spark.sql.catalogImplementation=hive --conf spark.app.name=spark-shared_process --conf spark.webui.yarn.useProxy=false --conf spark.driver.cores=1 --conf spark.executor.memory=1g --conf spark.master=local[*] --conf spark.jars.packages=graphframes:graphframes:0.6.0-spark2.2-s_2.11 --conf spark.driver.memory=1g --conf spark.executor.cores=1 /opt/zeppelin/interpreter/spark/spark-interpreter-0.10.0.jar 172.17.0.2 37229 spark-shared_process :\nLinea 372:  WARN [2022-10-23 15:25:26,343] ({main} ZeppelinConfiguration.java[<init>]:85) - Failed to load XML configuration, proceeding with a default,for a stacktrace activate the debug log\nLinea 373:  WARN [2022-10-23 15:25:27,180] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 374:  WARN [2022-10-23 15:25:27,181] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 375:  WARN [2022-10-23 15:25:27,182] ({main} ZeppelinConfiguration.java[getConfigFSDir]:653) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir\nLinea 376:  INFO [2022-10-23 15:27:30,897] ({SchedulerFactory2} SparkInterpreterLauncher.java[buildEnvFromProperties]:245) - buildEnvFromProperties: {PATH=/opt/conda/envs/python_3_with_R/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin, ZEPPELIN_LOG_DIR=/opt/zeppelin/logs, ZEPPELIN_WAR=/opt/zeppelin/zeppelin-web-0.10.0.war, ZEPPELIN_ENCODING=UTF-8, ZEPPELIN_SPARK_CONF=--conf|spark.executor.instances=2|--conf|spark.sql.catalogImplementation=hive|--conf|spark.app.name=spark-shared_process|--conf|spark.webui.yarn.useProxy=false|--conf|spark.driver.cores=1|--conf|spark.executor.memory=1g|--conf|spark.master=local[*]|--conf|spark.jars.packages=graphframes:graphframes:0.6.0-spark2.2-s_2.11|--conf|spark.driver.memory=1g|--conf|spark.executor.cores=1, JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64, JAVA_OPTS=  -Dfile.encoding=UTF-8 -Xmx1024m -Dlog4j.configuration=file:///opt/zeppelin/conf/log4j.properties -Dzeppelin.log.file=/opt/zeppelin/logs/zeppelin--localhost.log, TERM=screen, INTERPRETER_GROUP_ID=spark-shared_process, S_VERSION=2.4.8, Z_VERSION=0.10.0, LANG=en_US.UTF-8, JAVA_INTP_OPTS= -Dfile.encoding=UTF-8 -Dlog4j.configuration=file:///opt/zeppelin/conf/log4j.properties -Dlog4j.configurationFile=file:///opt/zeppelin/conf/log4j2.properties, PYSPARK_PYTHON=python, SPARK_HOME=/opt/spark, ZEPPELIN_CONF_DIR=/opt/zeppelin/conf, ZEPPELIN_NOTEBOOK_DIR=/notebook, STY=11.pts-0.localhost, ZEPPELIN_RUNNER=/usr/lib/jvm/java-8-openjdk-amd64/bin/java, PWD=/opt/zeppelin, ZEPPELIN_HOME=/opt/zeppelin, LOG_TAG=[ZEPPELIN_0.10.0]:, SHELL=/bin/bash, ZEPPELIN_INTP_MEM=-Xmx1024m, PYSPARK_DRIVER_PYTHON=python, ZEPPELIN_PID_DIR=/opt/zeppelin/run, ZEPPELIN_ANGULAR_WAR=/opt/zeppelin/zeppelin-web-angular-0.10.0.war, WINDOW=0, ZEPPELIN_MEM=-Xmx1024m, ZEPPELIN_INTERPRETER_CONNECT_TIMEOUT=120000, HOSTNAME=localhost, LC_ALL=en_US.UTF-8, ZEPPELIN_IDENT_STRING=, PYSPARK_PIN_THREAD=true, TERMCAP=SC|screen|VT 100/ANSI X3.64 virtual terminal:DO=\\E[%dB:LE=\\E[%dD:RI=\\E[%dC:UP=\\E[%dA:bs:bt=\\E[Z:cd=\\E[J:ce=\\E[K:cl=\\E[H\\E[J:cm=\\E[%i%d;%dH:ct=\\E[3g:do=^J:nd=\\E[C:pt:rc=\\E8:rs=\\Ec:sc=\\E7:st=\\EH:up=\\EM:le=^H:bl=^G:cr=^M:it#8:ho=\\E[H:nw=\\EE:ta=^I:is=\\E)0:li#13:co#137:am:xn:xv:LP:sr=\\EM:al=\\E[L:AL=\\E[%dL:cs=\\E[%i%d;%dr:dl=\\E[M:DL=\\E[%dM:dc=\\E[P:DC=\\E[%dP:im=\\E[4h:ei=\\E[4l:mi:IC=\\E[%d@:ks=\\E[?1h\\E=:ke=\\E[?1l\\E>:vi=\\E[?25l:ve=\\E[34h\\E[?25h:vs=\\E[34l:ti=\\E[?1049h:te=\\E[?1049l:us=\\E[4m:ue=\\E[24m:so=\\E[3m:se=\\E[23m:mb=\\E[5m:md=\\E[1m:mh=\\E[2m:mr=\\E[7m:me=\\E[m:ms:Co#8:pa#64:AF=\\E[3%dm:AB=\\E[4%dm:op=\\E[39;49m:AX:vb=\\Eg:G0:as=\\E(0:ae=\\E(B:ac=\\140\\140aaffggjjkkllmmnnooppqqrrssttuuvvwwxxyyzz{{||}}~~..--++,,hhII00:po=\\E[5i:pf=\\E[4i:Km=\\E[M:k0=\\E[10~:k1=\\EOP:k2=\\EOQ:k3=\\EOR:k4=\\EOS:k5=\\E[15~:k6=\\E[17~:k7=\\E[18~:k8=\\E[19~:k9=\\E[20~:k;=\\E[21~:F1=\\E[23~:F2=\\E[24~:kB=\\E[Z:kh=\\E[1~:@1=\\E[1~:kH=\\E[4~:@7=\\E[4~:kN=\\E[6~:kP=\\E[5~:kI=\\E[2~:kD=\\E[3~:ku=\\EOA:kd=\\EOB:kr=\\EOC:kl=\\EOD:km:, ZEPPELIN_ADDR=0.0.0.0, ZEPPELIN_INTERPRETER_REMOTE_RUNNER=bin/interpreter.sh, SHLVL=0, HOME=/opt/zeppelin}"
          },
          {
            "type": "HTML",
            "data": "<div class=\"result-alert alert-warning\" role=\"alert\"><button type=\"button\" class=\"close\" data-dismiss=\"alert\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></button><strong>Output is truncated</strong> to 102400 bytes. Learn more about <strong>ZEPPELIN_INTERPRETER_OUTPUT_LIMIT</strong></div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=68",
              "$$hashKey": "object:8760"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639463_2004030971",
      "id": "20201023-002107_2147167260",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "dateStarted": "2022-10-24T11:57:28+0000",
      "dateFinished": "2022-10-24T11:57:37+0000",
      "status": "FINISHED",
      "$$hashKey": "object:6899"
    },
    {
      "text": "print(s\"\"\"%html\n<img src=\"$baseDir/02_spark_core/log_linage.png\" alt=\"Drawing\" style=\"width: 70%;\"/>\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<img src=\"https://bitbucket.org/bigdata_famaf/diplodatos_bigdata/raw/HEAD/clases/02_spark_core/log_linage.png\" alt=\"Drawing\" style=\"width: 70%;\"/>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639463_1722553228",
      "id": "20171013-164802_1824704614",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6900"
    },
    {
      "text": "%pyspark\n\nuiHost = sc.getConf().get(\"spark.driver.host\")#.getOrElse(\"localhost\")\nuiPort = sc.uiWebUrl.split(\":\")[-1]\n\ntextNabuco = \"\"\"%html\nEjecutar celda y ver en Spark UI tareas y grafo de operaciones\n<a href=\"http://localhost:4040\">http://localhost(host):4040(port)</a><br>\nRecordar hacer el tunel ssh:<br>\nssh -vCN -L 4040:localhost:{} -l &lt;tu login&gt; nabucodonosor.ccad.unc.edu.ar\n\"\"\".format(uiPort)\n\ntextLocal = \"\"\"%html\nEjecutar celda y ver en Spark UI tareas y grafo de operaciones\n<a href=\"http://{}:{}\">http://{}(host):{}(port)</a>\n\"\"\".format(uiHost,uiPort,uiHost,uiPort)\n\nif uiHost == \"200.16.29.165\":\n    print(textNabuco)\nelse:\n    print(textLocal)\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "editorHide": true,
        "fontSize": 14,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "Ejecutar celda y ver en Spark UI tareas y grafo de operaciones\n<a href=\"http://localhost:4040\">http://localhost(host):4040(port)</a>\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639463_44153397",
      "id": "20171013-163432_1466279672",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6901"
    },
    {
      "title": "Implementación",
      "text": "%md\n\n* El RDD se distribuye en **particiones** en nodos del cluster (o fs local).\n* Se construye el **grafo de operaciones**.\n* Las **operaciones** se dividen en **tasks** (tareas).\n* A cada **partición** se le aplica una **task**.\n* Las tareas son ejecutadas por los executors en nodos (o threads locales).\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 14,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<ul>\n<li>El RDD se distribuye en <strong>particiones</strong> en nodos del cluster (o fs local).</li>\n<li>Se construye el <strong>grafo de operaciones</strong>.</li>\n<li>Las <strong>operaciones</strong> se dividen en <strong>tasks</strong> (tareas).</li>\n<li>A cada <strong>partición</strong> se le aplica una <strong>task</strong>.</li>\n<li>Las tareas son ejecutadas por los executors en nodos (o threads locales).</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639463_464655380",
      "id": "20171013-123100_1037283294",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6902"
    },
    {
      "title": "Stages",
      "text": "%md\n* El **grafo de operaciones** se subdivide en **stages**\n    - el limite entre las stages son las operaciones con shuffle.\n\n* Mas info en este [artículo](https://medium.com/@goyalsaurabh66/spark-basics-rdds-stages-tasks-and-dag-8da0f52f0454).",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 6,
        "editorMode": "ace/mode/markdown",
        "fontSize": 14,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<ul>\n<li>\n<p>El <strong>grafo de operaciones</strong> se subdivide en <strong>stages</strong></p>\n<ul>\n<li>el limite entre las stages son las operaciones con shuffle.</li>\n</ul>\n</li>\n<li>\n<p>Mas info en este <a href=\"https://medium.com/@goyalsaurabh66/spark-basics-rdds-stages-tasks-and-dag-8da0f52f0454\">artículo</a>.</p>\n</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639463_2031315962",
      "id": "paragraph_1634317918136_1777236417",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6903"
    },
    {
      "text": "%pyspark\nlines = sc.textFile(\"README.md\")\n\nwords = lines \\\n    .flatMap(lambda line: line.split(\" \")) \\\n    .filter(lambda word: word)\n\n#MapReduce\nwordCount = words \\\n    .map(lambda word: (word,1)) \\\n    .reduceByKey(lambda n,m: n+m)\n\nprint(wordCount.take(1))\n\n# Ver en SparkUI",
      "user": "anonymous",
      "dateUpdated": "2022-10-24T11:58:28+0000",
      "progress": 100,
      "config": {
        "lineNumbers": true,
        "tableHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6,
        "editorMode": "ace/mode/python",
        "fontSize": 14,
        "editorHide": false,
        "title": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[('#', 1)]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=69",
              "$$hashKey": "object:9002"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639463_1991912263",
      "id": "paragraph_1634318082132_1416467574",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "dateStarted": "2022-10-24T11:58:28+0000",
      "dateFinished": "2022-10-24T11:58:29+0000",
      "status": "FINISHED",
      "$$hashKey": "object:6904"
    },
    {
      "title": "Ejercicio",
      "text": "%md\n\n* Cree una celda nueva y copie en ella el último programa sin las línea 13.\n* Observe en Spark UI las tareas ejecutadas.\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<ul>\n<li>Cree una celda nueva y copie en ella el último programa sin las línea 13.</li>\n<li>Observe en Spark UI las tareas ejecutadas.</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639463_1808281026",
      "id": "20171013-165833_179635135",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6905"
    },
    {
      "text": "%pyspark\nlines = sc.textFile(\"README.md\")\n\nwords = lines \\\n    .flatMap(lambda line: line.split(\" \")) \\\n    .filter(lambda word: word)\n\n#MapReduce\nwordCount = words \\\n    .map(lambda word: (word,1)) \\\n    .reduceByKey(lambda n,m: n+m)",
      "user": "anonymous",
      "dateUpdated": "2022-10-24T11:59:05+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1666612739279_39035010",
      "id": "paragraph_1666612739279_39035010",
      "dateCreated": "2022-10-24T11:58:59+0000",
      "dateStarted": "2022-10-24T11:59:05+0000",
      "dateFinished": "2022-10-24T11:59:06+0000",
      "status": "FINISHED",
      "$$hashKey": "object:6906"
    },
    {
      "text": "%md\n## ~.- Evaluación Lazy\n\nEn Spark todas las **transformaciones** (`map`, `filter`, `union`, etc.) son evaluadas de forma **lazy**:\n\n* son acumuladas como *grafo de operaciones*\n* se ejecutan al momento de traer los datos al driver (`collect`, `take`, etc.)\n    - se llama a una **acción**.\n\nEsto permite:\n\n* hacer **optimizaciones**\n    - se computa solo lo que hace falta (tiene mucho sentido en Big Data)\n    - se hace un *pipeling* de transformaciones sin guardar resultados intermedios \n* recalcular las dependencias si hay algún fallo (resilencia)\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>~.- Evaluación Lazy</h2>\n<p>En Spark todas las <strong>transformaciones</strong> (<code>map</code>, <code>filter</code>, <code>union</code>, etc.) son evaluadas de forma <strong>lazy</strong>:</p>\n<ul>\n  <li>son acumuladas como <em>grafo de operaciones</em></li>\n  <li>se ejecutan al momento de traer los datos al driver (<code>collect</code>, <code>take</code>, etc.)\n    <ul>\n      <li>se llama a una <strong>acción</strong>.</li>\n    </ul>\n  </li>\n</ul>\n<p>Esto permite:</p>\n<ul>\n  <li>hacer <strong>optimizaciones</strong>\n    <ul>\n      <li>se computa solo lo que hace falta (tiene mucho sentido en Big Data)</li>\n      <li>se hace un <em>pipeling</em> de transformaciones sin guardar resultados intermedios</li>\n    </ul>\n  </li>\n  <li>recalcular las dependencias si hay algún fallo (resilencia)</li>\n</ul>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639464_724391932",
      "id": "20171013-171238_638394270",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6907"
    },
    {
      "title": "Logs análisis (muestra solo 2 lineas)",
      "text": "%pyspark\n\ninputRDD = sc.textFile(\"./logs/\") # RDD de entrada\nerrorRDD = inputRDD.filter(lambda line: \"ERROR\" in line) #  se crea un nuevo RDD\nconfigRDD = inputRDD.filter(lambda line: \"config\" in line) # se crea un nuevo RDD\n\nerrOrConfRDD = errorRDD.union(configRDD) \n\nfor ln, l in enumerate(errOrConfRDD.take(2)): # take(2) en vez de collect\n    print(\"Linea {}:\".format(ln), l)\n\n# Compara con primer programa en Spark UI\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-24T12:00:12+0000",
      "progress": 100,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 14,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Linea 0:  WARN [2022-10-24 00:00:57,110] ({SchedulerFactory20} NotebookServer.java[onStatusChange]:1986) - Job paragraph_1666564853357_1901912691 is finished, status: ERROR, exception: null, result: %text \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\nLinea 1:  INFO [2022-10-24 00:00:57,189] ({SchedulerFactory20} AbstractScheduler.java[runJob]:154) - Job paragraph_1666564853357_1901912691 finished by scheduler RemoteInterpreter-spark-shared_process-shared_session with status ERROR\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=70",
              "$$hashKey": "object:9194"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639464_1684512475",
      "id": "20201023-002121_604229819",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "dateStarted": "2022-10-24T12:00:13+0000",
      "dateFinished": "2022-10-24T12:00:14+0000",
      "status": "FINISHED",
      "$$hashKey": "object:6908"
    },
    {
      "title": "Ejercicio",
      "text": "%md\n\nComplete los `...` en el siguiente programa para contar la cantidad de veces que aparece la letra 'c' en los archivos en `./logs/`.\n\n#### Ayuda\n\n\n* Se puede usar el método `.filter` (ya visto en ejemplos anteriores) para crear un RDD solo con la letra C.\n* El método `count` de RDD cuenta la cantidad de elementos.\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Complete los <code>...</code> en el siguiente programa para contar la cantidad de veces que aparece la letra &lsquo;c&rsquo; en los archivos en <code>./logs/</code>.</p>\n<h4>Ayuda</h4>\n<ul>\n<li>Se puede usar el método <code>.filter</code> (ya visto en ejemplos anteriores) para crear un RDD solo con la letra C.</li>\n<li>El método <code>count</code> de RDD cuenta la cantidad de elementos.</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639464_1005886554",
      "id": "20171013-174042_1672649057",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6909"
    },
    {
      "text": "%pyspark\n\nlinesRDD = sc.textFile(\"./logs/\")\n\ncharsRDD = linesRDD \\\n            .flatMap(lambda l: l)\n\nonlyCRDD = charsRDD \\\n            .filter(lambda car: car==\"c\")\n\nprint(\"Aparecen {} letras c en los logs.\".format(onlyCRDD.count()))\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-24T12:10:44+0000",
      "progress": 90,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 14,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Aparecen 124331 letras c en los logs.\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=80",
              "$$hashKey": "object:9298"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639464_1711402320",
      "id": "20171013-175507_696892344",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "dateStarted": "2022-10-24T12:10:44+0000",
      "dateFinished": "2022-10-24T12:10:46+0000",
      "status": "FINISHED",
      "$$hashKey": "object:6910"
    },
    {
      "text": "%md\n## ~.- Persistencia\n\nSpark **recomputa** el grafo de dependencias cuando se llama una **acción**:",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>~.- Persistencia</h2>\n<p>Spark <strong>recomputa</strong> el grafo de dependencias cuando se llama una <strong>acción</strong>:</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639464_445217758",
      "id": "20171016-174448_43219511",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6911"
    },
    {
      "text": "%pyspark\n\ninput = sc.parallelize(range(30)) # Se crea la lista [0,...,29] y se lo convierte en RDD \n\nresult = input.map(lambda x: x*x)\n\nprint(\"La media es \", result.mean()) # computa los cuadrados\n\nfor r in result.collect():\n     print(r) # recomputa los cuadrados :(",
      "user": "anonymous",
      "dateUpdated": "2022-10-24T12:34:25+0000",
      "progress": 12,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 14,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "La media es  285.1666666666667\n0\n1\n4\n9\n16\n25\n36\n49\n64\n81\n100\n121\n144\n169\n196\n225\n256\n289\n324\n361\n400\n441\n484\n529\n576\n625\n676\n729\n784\n841\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=84",
              "$$hashKey": "object:9402"
            },
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=85",
              "$$hashKey": "object:9403"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639464_637706016",
      "id": "20201029-125345_2132006733",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "dateStarted": "2022-10-24T12:34:25+0000",
      "dateFinished": "2022-10-24T12:34:26+0000",
      "status": "FINISHED",
      "$$hashKey": "object:6912"
    },
    {
      "text": "%pyspark\n\nuiHost = sc.getConf().get(\"spark.driver.host\")#.getOrElse(\"localhost\")\nuiPort = sc.uiWebUrl.split(\":\")[-1]\n\ntextNabuco = \"\"\"%html\n(ver resultado en Spark UI\n<a href=\"http://localhost:4040\">http://localhost(host):4040(port)</a>)\n<br>\n<br>\nPara evitarlo Spark puede cachear los datos:\n\"\"\"\n\ntextLocal = \"\"\"%html\n(ver resultado en Spark UI\n<a href=\"http://{}:{}\">http://{}(host):{}(port)</a>)\n<br>\n<br>\nPara evitarlo Spark puede cachear los datos:\n\"\"\".format(uiHost,uiPort,uiHost,uiPort)\n\nif uiHost == \"200.16.29.165\":\n    print(textNabuco)\nelse:\n    print(textLocal)\n\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "(ver resultado en Spark UI\n<a href=\"http://localhost:4040\">http://localhost(host):4040(port)</a>)\n<br>\n<br>\nPara evitarlo Spark puede cachear los datos:\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639464_42996046",
      "id": "20171016-175252_2114983095",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6913"
    },
    {
      "text": "%pyspark\n\ninput = sc.parallelize(range(30)) # Se crea la lista [0,...,29] y se lo convierte en RDD \n\nresult = input.map(lambda x: x*x) \\\n              .setName(\"cuadrados\").cache() # cache de datos\n\nprint(\"La media es \", result.mean()) # computa los cuadrados\n\nfor r in result.collect():\n     print(r) # no recomputa el map :)",
      "user": "anonymous",
      "dateUpdated": "2022-10-24T12:34:53+0000",
      "progress": 12,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6,
        "editorMode": "ace/mode/python",
        "fontSize": 14,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "La media es  285.1666666666667\n0\n1\n4\n9\n16\n25\n36\n49\n64\n81\n100\n121\n144\n169\n196\n225\n256\n289\n324\n361\n400\n441\n484\n529\n576\n625\n676\n729\n784\n841\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=86",
              "$$hashKey": "object:9511"
            },
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=87",
              "$$hashKey": "object:9512"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639465_392494101",
      "id": "20201023-002155_1881617494",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "dateStarted": "2022-10-24T12:34:53+0000",
      "dateFinished": "2022-10-24T12:34:54+0000",
      "status": "FINISHED",
      "$$hashKey": "object:6914"
    },
    {
      "text": "%pyspark\n\nuiHost = sc.getConf().get(\"spark.driver.host\")#.getOrElse(\"localhost\")\nuiPort = sc.uiWebUrl.split(\":\")[-1]\n\ntextNabuco = \"\"\"%html\n%html\nVer resultado en Spark UI\n<a href=\"http://localhost:4040\">http://localhost(host):4040(port)</a>\n<br>\nObservar tambien green dots en Dag Visualization.\n\"\"\"\n\ntextLocal = \"\"\"%html\nVer resultado en Spark UI\n<a href=\"http://{}:{}\">http://{}(host):{}(port)</a>\n<br>\nObservar tambien green dots en Dag Visualization.\n\"\"\".format(uiHost,uiPort,uiHost,uiPort)\n\nif uiHost == \"200.16.29.165\":\n    print(textNabuco)\nelse:\n    print(textLocal)\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6,
        "editorMode": "ace/mode/python",
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "Ver resultado en Spark UI\n<a href=\"http://localhost:4040\">http://localhost(host):4040(port)</a>\n<br>\nObservar tambien green dots en Dag Visualization.\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639465_897324723",
      "id": "20171016-180034_191267646",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6915"
    },
    {
      "text": "%md\n\n## ~.- Implementación API Python\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>~.- Implementación API Python</h2>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639465_2040551870",
      "id": "20191128-173809_1077146591",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6916"
    },
    {
      "text": "%md\n\n* Spark esta originalmente implementado en Scala/Java.\n* `SparkContext` de Python usa [Py4J](https://www.py4j.org/), lanza JVM local y crea `JavaSparkContext`.\n* [Py4J](https://www.py4j.org/) solo se usa en driver.\n* En máquinas remotas los executors (Spark Workers en figura) corren en JVM asegurando resilencia.\n* Estas JVM lanzan procesos Python.\n* [Mas info](https://medium.com/@ketanvatsalya/a-scenic-route-through-pyspark-internals-feaf74ed660d).\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 6,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<ul>\n<li>Spark esta originalmente implementado en Scala/Java.</li>\n<li><code>SparkContext</code> de Python usa <a href=\"https://www.py4j.org/\">Py4J</a>, lanza JVM local y crea <code>JavaSparkContext</code>.</li>\n<li><a href=\"https://www.py4j.org/\">Py4J</a> solo se usa en driver.</li>\n<li>En máquinas remotas los executors (Spark Workers en figura) corren en JVM asegurando resilencia.</li>\n<li>Estas JVM lanzan procesos Python.</li>\n<li><a href=\"https://medium.com/@ketanvatsalya/a-scenic-route-through-pyspark-internals-feaf74ed660d\">Mas info</a>.</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639465_257292236",
      "id": "20191128-175341_672335059",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6917"
    },
    {
      "text": "print(s\"\"\"%html\n<img src=\"$baseDir/02_spark_core/python-spark.png\" alt=\"Drawing\" style=\"width: 70%;\"/>\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<img src=\"https://bitbucket.org/bigdata_famaf/diplodatos_bigdata/raw/HEAD/clases/02_spark_core/python-spark.png\" alt=\"Drawing\" style=\"width: 70%;\"/>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639466_1625190636",
      "id": "20191128-175407_1271062039",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6918"
    },
    {
      "title": "Ejercicio",
      "text": "%md\nComplete el siguiente programa para que cuente la cantidad de lineas que comienzan con la palabra `INFO`, `WARN` y `ERROR`.\n\nTambién, haga cache de los RDD para hacer el programa más eficiente. \n",
      "user": "anonymous",
      "dateUpdated": "2022-10-24T12:42:14+0000",
      "progress": 0,
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": false,
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Complete el siguiente programa para que cuente la cantidad de lineas que comienzan con la palabra <code>INFO</code>, <code>WARN</code> y <code>ERROR</code>.</p>\n<p>También, haga cache de los RDD para hacer el programa más eficiente.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639466_1077750166",
      "id": "20171016-193030_671507369",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6919"
    },
    {
      "text": "%pyspark\n\nlinesRDD = sc.textFile(\"./logs/\") # RDD de entrada\n\nlinesStrip = linesRDD.map(lambda l: l.strip()).cache() # Borro espacios en borde\n\nlinesInfo = linesStrip.filter(lambda l: l.startswith(\"INFO\")).setName(\"Info\").cache()\n\nlinesWarn = linesStrip.filter(lambda l: l.startswith(\"WARN\")).setName(\"Warn\").cache() # Completar\n\nlinesError = linesStrip.filter(lambda l: l.startswith(\"ERROR\")).setName(\"Error\").cache() # Completar\n\nprint(\"Cantidad de lineas INFO: \", linesInfo.count())\n\nprint(\"Cantidad de lineas WARN: \", linesWarn.count()) #Completar\n\nprint(\"Cantidad de lineas ERROR: \", linesError.count())  #Completar\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-24T12:45:33+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 14,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Cantidad de lineas INFO:  33115\nCantidad de lineas WARN:  392\nCantidad de lineas ERROR:  33\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=91",
              "$$hashKey": "object:9806"
            },
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=92",
              "$$hashKey": "object:9807"
            },
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=93",
              "$$hashKey": "object:9808"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639467_477459478",
      "id": "20191123-214023_2104486544",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "dateStarted": "2022-10-24T12:45:33+0000",
      "dateFinished": "2022-10-24T12:45:36+0000",
      "status": "FINISHED",
      "$$hashKey": "object:6920"
    },
    {
      "title": "Ejercicio",
      "text": "%md\nEl archivo en `~/diplodatos_bigdata/ds/flights.csv` contiene información de vuelos realizados en 2008 (solo 100.000), uno por línea.\n\nLos datos estan separados por coma y la columna `Cancelled` (la 22) tiene un `1` si el vuelo fue cancelado. Además si el vuelo fue redirigido se indica con '1' en la columna `Diverted` (la 24).\n\nCompletar el siguiente programa que devuelve el porcentaje de vuelos cancelados y el porcentaje de redirigidos.\n\nUtilizar cache si lo cree conveniente.\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false,
          "completionKey": "TAB"
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>El archivo en <code>~/diplodatos_bigdata/ds/flights.csv</code> contiene información de vuelos realizados en 2008 (solo 100.000), uno por línea.</p>\n<p>Los datos estan separados por coma y la columna <code>Cancelled</code> (la 22) tiene un <code>1</code> si el vuelo fue cancelado. Además si el vuelo fue redirigido se indica con &lsquo;1&rsquo; en la columna <code>Diverted</code> (la 24).</p>\n<p>Completar el siguiente programa que devuelve el porcentaje de vuelos cancelados y el porcentaje de redirigidos.</p>\n<p>Utilizar cache si lo cree conveniente.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639467_1941656610",
      "id": "20171016-224717_280061616",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6921"
    },
    {
      "text": "{val input = spark.read.format(\"csv\").option(\"header\", \"true\").load(s\"${homeDir}/diplodatos_bigdata/ds/flights.csv\").sample(false,0.0005)\nz.show(input,10)}",
      "user": "anonymous",
      "dateUpdated": "2022-10-25T12:28:57+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {
                    "columns": [
                      {
                        "name": "Year0",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "Month1",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "DayofMonth2",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "DayOfWeek3",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "DepTime4",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "CRSDepTime5",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "ArrTime6",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "CRSArrTime7",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "UniqueCarrier8",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "FlightNum9",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "TailNum10",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "ActualElapsedTime11",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "CRSElapsedTime12",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "AirTime13",
                        "visible": true,
                        "width": "*",
                        "sort": {
                          "priority": 0,
                          "direction": "desc"
                        },
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "ArrDelay14",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "DepDelay15",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "Origin16",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "Dest17",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "Distance18",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "TaxiIn19",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "TaxiOut20",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "Cancelled21",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "CancellationCode22",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "Diverted23",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "CarrierDelay24",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "WeatherDelay25",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "NASDelay26",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "SecurityDelay27",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "LateAircraftDelay28",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      }
                    ],
                    "scrollFocus": {},
                    "selection": [],
                    "grouping": {
                      "grouping": [],
                      "aggregations": [],
                      "rowExpandedStates": {}
                    },
                    "treeView": {},
                    "pagination": {
                      "paginationCurrentPage": 1,
                      "paginationPageSize": 250
                    }
                  },
                  "tableColumnTypeState": {
                    "names": {
                      "Year": "string",
                      "Month": "string",
                      "DayofMonth": "string",
                      "DayOfWeek": "string",
                      "DepTime": "string",
                      "CRSDepTime": "string",
                      "ArrTime": "string",
                      "CRSArrTime": "string",
                      "UniqueCarrier": "string",
                      "FlightNum": "string",
                      "TailNum": "string",
                      "ActualElapsedTime": "string",
                      "CRSElapsedTime": "string",
                      "AirTime": "string",
                      "ArrDelay": "string",
                      "DepDelay": "string",
                      "Origin": "string",
                      "Dest": "string",
                      "Distance": "string",
                      "TaxiIn": "string",
                      "TaxiOut": "string",
                      "Cancelled": "string",
                      "CancellationCode": "string",
                      "Diverted": "string",
                      "CarrierDelay": "string",
                      "WeatherDelay": "string",
                      "NASDelay": "string",
                      "SecurityDelay": "string",
                      "LateAircraftDelay": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "Year\tMonth\tDayofMonth\tDayOfWeek\tDepTime\tCRSDepTime\tArrTime\tCRSArrTime\tUniqueCarrier\tFlightNum\tTailNum\tActualElapsedTime\tCRSElapsedTime\tAirTime\tArrDelay\tDepDelay\tOrigin\tDest\tDistance\tTaxiIn\tTaxiOut\tCancelled\tCancellationCode\tDiverted\tCarrierDelay\tWeatherDelay\tNASDelay\tSecurityDelay\tLateAircraftDelay\n2008\t1\t6\t7\t1801\t1805\t1941\t1955\tWN\t172\tN767SW\t160\t170\t146\t-14\t-4\tMCO\tMDW\t989\t4\t10\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t6\t7\t1023\t1010\t1136\t1135\tWN\t752\tN348SW\t73\t85\t63\t1\t13\tOAK\tLAS\t407\t4\t6\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t6\t7\t838\t830\t955\t945\tWN\t304\tN342SW\t77\t75\t56\t10\t8\tOAK\tLAX\t337\t5\t16\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t6\t7\t745\t745\t929\t930\tWN\t1586\tN318SW\t164\t165\t149\t-1\t0\tSTL\tABQ\t934\t4\t11\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t7\t1\t1340\t1340\t1440\t1440\tWN\t35\tN519SW\t60\t60\t47\t0\t0\tLBB\tDAL\t293\t3\t10\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t8\t2\t1850\t1850\t2041\t2045\tWN\t102\tN331SW\t231\t235\t219\t-4\t0\tMCI\tSMF\t1442\t5\t7\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t9\t3\t1834\t1835\t1943\t1940\tWN\t55\tN502SW\t69\t65\t54\t3\t-1\tAMA\tDAL\t324\t5\t10\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t9\t3\t923\t925\t1046\t1055\tWN\t1188\tN200WN\t83\t90\t72\t-9\t-2\tHOU\tBHM\t570\t2\t9\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t10\t4\t1600\t1600\t2337\t2350\tWN\t416\tN738CB\t277\t290\t254\t-13\t0\tLAS\tPVD\t2363\t4\t19\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t10\t4\t1154\t1155\t1314\t1310\tWN\t876\tN427WN\t80\t75\t68\t4\t-1\tONT\tSMF\t389\t4\t8\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t12\t6\t855\t825\t955\t930\tWN\t171\tN611SW\t60\t65\t49\t25\t30\tBUF\tBWI\t281\t4\t7\t0\tnull\t0\t25\t0\t0\t0\t0\n2008\t1\t12\t6\t900\t755\t957\t905\tWN\t2724\tN788SA\t57\t70\t46\t52\t65\tPIT\tPHL\t267\t4\t7\t0\tnull\t0\t52\t0\t0\t0\t0\n2008\t1\t13\t7\t1924\t1835\t2049\t2000\tWN\t2133\tN506SW\t85\t85\t49\t49\t49\tPHL\tPIT\t267\t6\t30\t0\tnull\t0\t8\t0\t0\t0\t41\n2008\t1\t13\t7\t1727\t1705\t1735\t1725\tWN\t3586\tN221WN\t68\t80\t54\t10\t22\tPHX\tLAX\t370\t7\t7\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t13\t7\tNA\t635\tNA\t805\tWN\t3512\tnull\tNA\t90\tNA\tNA\tNA\tSAN\tSFO\t447\tNA\tNA\t1\tB\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t14\t1\t637\t635\t748\t745\tWN\t3138\tN355SW\t71\t70\t59\t3\t2\tCMH\tBWI\t336\t4\t8\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t15\t2\t2008\t2000\t2100\t2055\tWN\t56\tN502SW\t52\t55\t39\t5\t8\tHOU\tDAL\t239\t4\t9\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t15\t2\t1658\t1700\t1815\t1830\tWN\t1435\tN683SW\t137\t150\t123\t-15\t-2\tSAT\tPHX\t843\t6\t8\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t16\t3\t1432\t1435\t1759\t1815\tWN\t2205\tN235WN\t147\t160\t131\t-16\t-3\tABQ\tMDW\t1121\t8\t8\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t16\t3\t1302\t1305\t1427\t1430\tWN\t1541\tN228WN\t85\t85\t74\t-3\t-3\tOAK\tLAS\t407\t4\t7\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t17\t4\t1720\t1705\t1848\t1835\tWN\t369\tN735SA\t88\t90\t69\t13\t15\tSAN\tSFO\t447\t6\t13\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t20\t7\t1437\t1435\t2013\t2025\tWN\t3576\tN286WN\t216\t230\t203\t-12\t2\tLAX\tMDW\t1750\t6\t7\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t20\t7\t1101\t1100\t1404\t1440\tWN\t1047\tN495WN\t303\t340\t290\t-36\t1\tPHL\tPHX\t2075\t4\t9\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t23\t3\t725\t725\t1047\t1050\tWN\t3597\tN705SW\t202\t205\t188\t-3\t0\tPVD\tFLL\t1188\t4\t10\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t26\t6\t1511\t1445\t1740\t1735\tWN\t802\tN661SW\t89\t110\t74\t5\t26\tLAS\tBOI\t520\t3\t12\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t26\t6\t2017\t2015\t2112\t2115\tWN\t744\tN660SW\t55\t60\t42\t-3\t2\tSTL\tMDW\t251\t5\t8\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t26\t6\t630\t630\t723\t720\tWN\t828\tN271WN\t113\t110\t102\t3\t0\tTPA\tBNA\t612\t4\t7\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t30\t3\t639\t635\t748\t745\tWN\t3138\tN365SW\t69\t70\t52\t3\t4\tCMH\tBWI\t336\t2\t15\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t30\t3\t1549\t1550\t1642\t1655\tWN\t1595\tN212WN\t53\t65\t40\t-13\t-1\tLAS\tSAN\t258\t3\t10\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t31\t4\t735\t730\t914\t905\tWN\t1479\tN301SW\t159\t155\t148\t9\t5\tABQ\tOAK\t889\t3\t8\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t13\t7\t1846\t1825\t1948\t1938\tXE\t149\tN19554\t62\t73\t50\t10\t21\tMRY\tLGB\t283\t4\t8\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t2\t3\t1435\t1435\t1524\t1537\tXE\t502\tN16178\t109\t122\t90\t-13\t0\tSAT\tABQ\t609\t5\t14\t0\tnull\t0\tNA\tNA\tNA\tNA\tNA\n2008\t1\t1\t2\t1653\t1525\t1738\t1617\tXE\t600\tN12563\t105\t112\t91\t81\t88\tJAX\tMSY\t513\t6\t8\t0\tnull\t0\t0\t0\t0\t0\t81\n"
          },
          {
            "type": "TEXT",
            "data": ""
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639467_76212667",
      "id": "20191123-214248_1978352340",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6922"
    },
    {
      "title": "",
      "text": "%pyspark\n\ninput = sc.textFile(\"/diplodatos_bigdata/ds/flights.csv\") # Completar el path\n\nnTotal = input.count() - 1 # la primer fila tiene el nombre de las columnas\n\nparsed = input.map(lambda l: l.split(\",\")).cache()\n\ncancel = parsed.filter(lambda l: l[21] == \"1\") # Completar\n\nredir = parsed.filter(lambda l: l[23] == \"1\") # Completar\n\nnCancel = cancel.count()\nnRedir = redir.count()\n\nprint(\"cancelados = {}%\".format(float(nCancel) * 100 / nTotal))\nprint(\"redireccionados = {}%\".format(float(nRedir) * 100 / nTotal)) # Completar\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-24T13:23:21+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 14,
        "editorHide": false,
        "title": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "cancelados = 1.142%\nredireccionados = 0.16%\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=135",
              "$$hashKey": "object:10020"
            },
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=136",
              "$$hashKey": "object:10021"
            },
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=137",
              "$$hashKey": "object:10022"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639468_1120520297",
      "id": "20191124-133441_1910745321",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "dateStarted": "2022-10-24T13:23:21+0000",
      "dateFinished": "2022-10-24T13:23:23+0000",
      "status": "FINISHED",
      "$$hashKey": "object:6923"
    },
    {
      "title": "Ejercicio",
      "text": "%md\nLa columna 14 del mismo archivo tiene el tiempo del vuelo en minutos. Calcular el máximo.\n\n#### Ayuda\n\n* Busque en la documentacion de la [API RDD](http://spark.apache.org/docs/2.2.1/api/python/pyspark.html#pyspark.RDD) una acción para calcular el máximo.\n* Ojo que puede haber valores no definidos.\n",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>La columna 14 del mismo archivo tiene el tiempo del vuelo en minutos. Calcular el máximo.</p>\n<h4>Ayuda</h4>\n<ul>\n  <li>Busque en la documentacion de la <a href=\"http://spark.apache.org/docs/2.2.1/api/python/pyspark.html#pyspark.RDD\">API RDD</a> una acción para calcular el máximo.</li>\n  <li>Ojo que puede haber valores no definidos.</li>\n</ul>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639468_1833753026",
      "id": "20171016-232257_285172371",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6924"
    },
    {
      "text": "%pyspark\n\nAirTime_list = parsed.map(lambda l: l[13]).collect()\n\nString_numbers = [s for s in AirTime_list if s.isdigit()]\n\nIntegers = [int(i) for i in String_numbers]\n\nmax_fly = max(Integers)\n\nprint(\"El tiempo de vuelo máximo fue de {} minutos\".format(max_fly))",
      "user": "anonymous",
      "dateUpdated": "2022-10-26T12:32:22+0000",
      "progress": 100,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 14,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "El tiempo de vuelo máximo fue de 369 minutos\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://localhost:4040/jobs/job?id=319",
              "$$hashKey": "object:13279"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1666617831463_1795456072",
      "id": "paragraph_1666617831463_1795456072",
      "dateCreated": "2022-10-24T13:23:51+0000",
      "dateStarted": "2022-10-26T12:32:22+0000",
      "dateFinished": "2022-10-26T12:32:23+0000",
      "status": "FINISHED",
      "$$hashKey": "object:6925"
    },
    {
      "title": "FIN",
      "text": "//val baseDir=\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases\"\nval baseDir=\"https://bitbucket.org/bigdata_famaf/diplodatos_bigdata/raw/HEAD/clases\"\nval homeDir=\"/home/damian\"\n\nz.put(\"baseDir\", baseDir)\nprint(\"\"\"%html\n<script>\n    var heads = document.getElementsByTagName('h2');\n    var numHeads = heads.length;\n    var inner = \"\";\n    var i = 1;\n    var j = 0;\n    while (i < numHeads){\n        inner = heads[i].innerHTML;\n        if (inner.match(\"(~|\\d+)\\.-\") != -1 ) {\n            console.log(inner)\n            j++;\n            heads[i].innerHTML = inner.replace(/(~|\\d+)\\.-/,\"\"+j+\".-\");\n        }\n        i++\n    }\n</script>\n\"\"\")",
      "user": "anonymous",
      "dateUpdated": "2022-10-16T21:43:59+0000",
      "progress": 0,
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<script>\n    var heads = document.getElementsByTagName('h2');\n    var numHeads = heads.length;\n    var inner = \"\";\n    var i = 1;\n    var j = 0;\n    while (i < numHeads){\n        inner = heads[i].innerHTML;\n        if (inner.match(\"(~|\\d+)\\.-\") != -1 ) {\n            console.log(inner)\n            j++;\n            heads[i].innerHTML = inner.replace(/(~|\\d+)\\.-/,\"\"+j+\".-\");\n        }\n        i++\n    }\n</script>\nbaseDir: String = https://bitbucket.org/bigdata_famaf/diplodatos_bigdata/raw/HEAD/clases\nhomeDir: String = /home/damian\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1665956639469_1957918532",
      "id": "20171010-191336_1667301043",
      "dateCreated": "2022-10-16T21:43:59+0000",
      "status": "READY",
      "$$hashKey": "object:6927"
    }
  ],
  "name": "Clase 02 - Spark Core",
  "id": "2HGWJJS1M",
  "defaultInterpreterGroup": "spark",
  "version": "0.10.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/Clase 02 - Spark Core"
}